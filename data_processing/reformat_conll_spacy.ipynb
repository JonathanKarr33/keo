{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "844543f3-b77f-4242-acea-5dc356a2333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61f4838e-c558-45c8-a46e-18646e36f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/FAA_data/Maintenance_Text_data_nona.csv\")[\"c119\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19003a07-9963-427b-b6ac-bad1a0285e0a",
   "metadata": {},
   "source": [
    "1. Document ID: This is a variation on the document filename\n",
    "2. Part number: Some files are divided into multiple parts numbered as 000, 001, 002, ... etc.\n",
    "3. Word number\n",
    "4. Word itself: This is the token as segmented/tokenized in the Treebank. Initially the *_skel file contain the placeholder [WORD] which gets replaced by the actual token from the Treebank which is part of the OntoNotes release.\n",
    "5. Part-of-Speech\n",
    "6. Parse bit: This is the bracketed structure broken before the first open parenthesis in the parse, and the word/part-of-speech leaf replaced with a *. The full parse can be created by substituting the asterix with the \"([pos] [word])\" string (or leaf) and concatenating the items in the rows of that column.\n",
    "7. Predicate lemma: The predicate lemma is mentioned for the rows for which we have semantic role information. All other rows are marked with a \"-\"\n",
    "8. Predicate Frameset ID: This is the PropBank frameset ID of the predicate in Column 7.\n",
    "9. Word sense: This is the word sense of the word in Column 3.\n",
    "10. Speaker/Author: This is the speaker or author name where available. Mostly in Broadcast Conversation and Web Log data.\n",
    "11. Named Entities: These columns identifies the spans representing various named entities.\n",
    "\n",
    "12 - N Predicate Arguments: There is one column each of predicate argument structure information for the predicate mentioned in Column 7.\n",
    "\n",
    "N. Coreference:oreference chain information encoded in a parenthesis structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40cf973-57b4-46ee-afce-7e78c20f102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Document ID\tPart number\tWord number\tWord itself\tPart-of-Speech\tParse bit\tPredicate lemma\tPredicate Frameset ID\tWord sense\tSpeaker/Author\tNamed Entities\tPredicate Arguments\tCoreference\n",
      "1\t0\t1\tThis\tPRON\t(PRON This )\t-\t-\t-\t-\t-\t-\t-\n",
      "2\t0\t2\tis\tAUX\t(AUX is (PRON This ) (NOUN sentence (DET an ) (NOUN example )) .)\t-\t-\t-\t-\t-\t-\t-\n",
      "3\t0\t3\tan\tDET\t(DET an )\t-\t-\t-\t-\t-\t-\t-\n",
      "4\t0\t4\texample\tNOUN\t(NOUN example )\t-\t-\t-\t-\t-\t-\t-\n",
      "5\t0\t5\tsentence\tNOUN\t(NOUN sentence (DET an ) (NOUN example ))\t-\t-\t-\t-\t-\t-\t-\n",
      "6\t0\t6\t.\tPUNCT\t.\t-\t-\t-\t-\t-\t-\t-\n",
      "7\t0\t7\tAnother\tDET\t(DET Another )\t-\t-\t-\t-\t-\t-\t-\n",
      "8\t0\t8\tsentence\tNOUN\t(NOUN sentence (DET Another ))\t-\t-\t-\t-\t-\t-\t-\n",
      "9\t0\t9\tfollows\tVERB\t(VERB follows (NOUN sentence (DET Another )) .)\t-\t-\t-\t-\t-\t-\t-\n",
      "10\t0\t10\t.\tPUNCT\t.\t-\t-\t-\t-\t-\t-\t-\n"
     ]
    }
   ],
   "source": [
    "def get_parse_bit(token):\n",
    "    if token.dep_ == 'punct':\n",
    "        return token.text\n",
    "    elif token.children:\n",
    "        return f\"({token.pos_} {token.text} {' '.join(get_parse_bit(child) for child in token.children)})\"\n",
    "    else:\n",
    "        return f\"({token.pos_} {token.text})\"\n",
    "\n",
    "def convert_to_conll12(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "\n",
    "    print(\"\\t\".join([\"# Document ID\", \"Part number\", \"Word number\", \"Word itself\", \"Part-of-Speech\", \"Parse bit\",\n",
    "                     \"Predicate lemma\", \"Predicate Frameset ID\", \"Word sense\", \"Speaker/Author\", \"Named Entities\",\n",
    "                     \"Predicate Arguments\", \"Coreference\"]))\n",
    "\n",
    "    for i, token in enumerate(doc):\n",
    "        parse_bit = get_parse_bit(token)\n",
    "        row = [str(i + 1), \"0\", str(i + 1), token.text, token.pos_, parse_bit, \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\"]\n",
    "        print(\"\\t\".join(row))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"This is an example sentence. Another sentence follows.\"\n",
    "convert_to_conll12(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7877af-72cf-43f4-a62b-e6675b32f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'([A-Z])([,\\.\\)])([A-Z])')\n",
    "\n",
    "for irow in range(len(data)):\n",
    "    data[irow] = re.sub(pattern, r'\\1\\2 \\3',data[irow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecaee9-bd52-488d-be52-9c094e17ef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       TAILWHEEL COCKED RIGHT PRIOR TO TKOF.         ...\n",
       "1       TOW PLANE BECAME AIRBORNE THEN SETTLED. STUDEN...\n",
       "2       2ND ILS APCH, ACFT'S G/S INOP. LOM TUNED TO WR...\n",
       "3       PLT NOTED SOFT R BRAKE PEDAL DRG TAXI TO TKOF....\n",
       "4       TAXI OFF HARD SFC DUE TFC R MAIN GR BROKE THRO...\n",
       "                              ...                        \n",
       "2743    (-23) A/C RELOCATED TO NEW HANGAR TO CHECK SIZ...\n",
       "2744    (-23) ON 2/23/08 @ APPROXIMATELY 2130 DURING T...\n",
       "2745    (-23) PILOT TOOK OFF FOR LEESBURG AIRPORT AND ...\n",
       "2746    (-23) OWNER FORGOT TO FASTEN THE LOWER LEFT 4 ...\n",
       "2747    (-23) THE AIRCRAFT EXPERIENCED SEVERE TURBULAN...\n",
       "Name: c119, Length: 2748, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab39edc-0948-43ea-a4f7-c16a49a5f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAILWHEEL', 'COCKED', 'RIGHT', 'PRIOR', 'TO', 'TKOF', '\\\\.']\n"
     ]
    }
   ],
   "source": [
    "for irow in range(len(data)):\n",
    "    split_entry = data[irow].split()\n",
    "    new_entry = []\n",
    "    for word in split_entry:\n",
    "        if word[-1] == '.':\n",
    "            new_entry.append(word[:-1])\n",
    "            new_entry.append(r'\\.')\n",
    "        else:\n",
    "            new_entry.append(word)\n",
    "    print(new_entry)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e7b2b38-812c-4a99-b68d-ef08e1b8d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faa\t0000\t0\tTAILWHEEL\n",
      "faa\t0000\t1\tCOCKED\n",
      "faa\t0000\t2\tRIGHT\n",
      "faa\t0000\t3\tPRIOR\n",
      "faa\t0000\t4\tTO\n",
      "faa\t0000\t5\tTKOF.\n",
      "faa\t0001\t0\tTOW\n",
      "faa\t0001\t1\tPLANE\n",
      "faa\t0001\t2\tBECAME\n",
      "faa\t0001\t3\tAIRBORNE\n",
      "faa\t0001\t4\tTHEN\n",
      "faa\t0001\t5\tSETTLED.STUDENT\n",
      "faa\t0001\t6\tTHOUGHT\n",
      "faa\t0001\t7\tTOW\n",
      "faa\t0001\t8\tIN\n",
      "faa\t0001\t9\tTROUBLE\n",
      "faa\t0001\t10\t&\n",
      "faa\t0001\t11\tRELEASED.HIT\n",
      "faa\t0001\t12\tTREE.\n",
      "faa\t0002\t0\t2ND\n",
      "faa\t0002\t1\tILS\n",
      "faa\t0002\t2\tAPCH,ACFT'S\n",
      "faa\t0002\t3\tG/S\n",
      "faa\t0002\t4\tINOP.LOM\n",
      "faa\t0002\t5\tTUNED\n",
      "faa\t0002\t6\tTO\n",
      "faa\t0002\t7\tWRONG\n",
      "faa\t0002\t8\tFREQ.\n",
      "faa\t0003\t0\tPLT\n",
      "faa\t0003\t1\tNOTED\n",
      "faa\t0003\t2\tSOFT\n",
      "faa\t0003\t3\tR\n",
      "faa\t0003\t4\tBRAKE\n",
      "faa\t0003\t5\tPEDAL\n",
      "faa\t0003\t6\tDRG\n",
      "faa\t0003\t7\tTAXI\n",
      "faa\t0003\t8\tTO\n",
      "faa\t0003\t9\tTKOF.FLT\n",
      "faa\t0003\t10\tRTND\n",
      "faa\t0003\t11\tSPRINGFIELD\n",
      "faa\t0003\t12\tDUE\n",
      "faa\t0003\t13\tSOFT\n",
      "faa\t0003\t14\tBRAKE\n",
      "faa\t0003\t15\tSTRONG\n",
      "faa\t0003\t16\tWINDS\n",
      "faa\t0003\t17\tBOS\n",
      "faa\t0004\t0\tTAXI\n",
      "faa\t0004\t1\tOFF\n",
      "faa\t0004\t2\tHARD\n",
      "faa\t0004\t3\tSFC\n",
      "faa\t0004\t4\tDUE\n",
      "faa\t0004\t5\tTFC\n",
      "faa\t0004\t6\tR\n",
      "faa\t0004\t7\tMAIN\n",
      "faa\t0004\t8\tGR\n",
      "faa\t0004\t9\tBROKE\n",
      "faa\t0004\t10\tTHROUGH\n",
      "faa\t0004\t11\tROOF\n",
      "faa\t0004\t12\tOF\n",
      "faa\t0004\t13\tA\n",
      "faa\t0004\t14\tWASHED\n",
      "faa\t0004\t15\tOUT\n",
      "faa\t0004\t16\tUNDERGROUND\n",
      "faa\t0004\t17\tTUNNEL.\n"
     ]
    }
   ],
   "source": [
    "docid = \"faa\"\n",
    "\n",
    "#for irow in range(len(data)):\n",
    "for irow in range(5):\n",
    "    for iword, word in enumerate(data[irow].split()):\n",
    "        print(f\"{docid}\\t{irow:04}\\t{iword}\\t{word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4a6f9-c36f-4351-92fd-fd6582bd164a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reformat_conll",
   "language": "python",
   "name": "reformat_conll"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
