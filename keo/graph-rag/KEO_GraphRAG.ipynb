{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a7a50-1c03-443f-a1fa-5036a7a12fcb",
   "metadata": {
    "id": "030a7a50-1c03-443f-a1fa-5036a7a12fcb"
   },
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import typing\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# NLP and Embedding Libraries\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Graph Libraries\n",
    "import networkx as nx\n",
    "from networkx.algorithms import shortest_paths\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "openai_api_key = 'Key goes here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "NayPvat2LsMr",
   "metadata": {
    "id": "NayPvat2LsMr"
   },
   "outputs": [],
   "source": [
    "class DataPreparer:\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize the DataPreparer with the CSV file path.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.raw_data = None\n",
    "        self.cleaned_data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load the data from the CSV file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.raw_data = pd.read_csv(self.file_path)\n",
    "            print(\"Data loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        Perform cleaning operations on the dataset:\n",
    "        - Drop unnecessary columns.\n",
    "        - Rename columns for readability.\n",
    "        - Handle missing values.\n",
    "        \"\"\"\n",
    "        if self.raw_data is None:\n",
    "            print(\"No data to clean. Please load data first.\")\n",
    "            return\n",
    "\n",
    "        self.cleaned_data = self.raw_data.drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "        self.cleaned_data.rename(\n",
    "            columns={\n",
    "                'c119': 'Incident_Description',\n",
    "                'c77': 'Contributing_Factor',\n",
    "                'c79': 'Event_Context',\n",
    "                'c81': 'Role',\n",
    "                'c146': 'Weight_Category',\n",
    "                'c148': 'Aircraft_Type',\n",
    "                'c150': 'Power_Characteristics',\n",
    "                'c161': 'Outcome',\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        self.cleaned_data.fillna('Unknown', inplace=True)\n",
    "        print(\"Data cleaned successfully!\")\n",
    "\n",
    "    def normalize_text(self):\n",
    "        \"\"\"\n",
    "        Normalize text fields:\n",
    "        - Convert text to lowercase.\n",
    "        - Remove special characters.\n",
    "        \"\"\"\n",
    "        if self.cleaned_data is None:\n",
    "            print(\"No data to normalize. Please clean data first.\")\n",
    "            return\n",
    "\n",
    "        def normalize(text):\n",
    "            text = str(text).lower()  # Ensure text is a string before normalization\n",
    "            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "            return text.strip()\n",
    "\n",
    "        for column in self.cleaned_data.columns:\n",
    "            if self.cleaned_data[column].dtype == \"object\":\n",
    "                self.cleaned_data[column] = self.cleaned_data[column].apply(normalize)\n",
    "\n",
    "        print(\"Text fields normalized successfully!\")\n",
    "\n",
    "    def get_prepared_data(self):\n",
    "        \"\"\"\n",
    "        Return the cleaned and prepared data as a Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        if self.cleaned_data is None:\n",
    "            print(\"Data is not prepared yet. Please clean and normalize the data.\")\n",
    "            return None\n",
    "        return self.cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "_kzvz97a0flu",
   "metadata": {
    "id": "_kzvz97a0flu"
   },
   "outputs": [],
   "source": [
    "class DynamicGraphProcessor:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize the graph processor with prepared data.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    def extract_entities_and_relationships(self, text):\n",
    "        \"\"\"\n",
    "        Enhanced entity and relationship extraction.\n",
    "        \"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        relationships = []\n",
    "\n",
    "        # Improved entity extraction\n",
    "        entities = []\n",
    "        for ent in doc.ents:\n",
    "            if not ent.text.lower() in ['on', 'in', 'of', 'the', 'a', 'an']:  # Filter common words\n",
    "                entities.append((ent.text, ent.label_))\n",
    "\n",
    "        # Enhanced relationship extraction\n",
    "        for token in doc:\n",
    "            # Expanded dependency patterns\n",
    "            if token.dep_ in (\"nsubj\", \"dobj\", \"pobj\", \"amod\", \"compound\"):\n",
    "                if not token.is_stop and token.head.pos_ in ['VERB', 'NOUN']:  # More specific conditions\n",
    "                    subject = token.head.text\n",
    "                    obj = token.text\n",
    "                    rel = token.dep_\n",
    "\n",
    "                    # Get fuller context\n",
    "                    context = \" \".join([t.text for t in token.head.subtree\n",
    "                                     if not t.is_stop])  # Remove stopwords from context\n",
    "\n",
    "                    # Add more semantic information\n",
    "                    relationships.append({\n",
    "                        \"subject\": subject,\n",
    "                        \"relation\": rel,\n",
    "                        \"object\": obj,\n",
    "                        \"context\": context,\n",
    "                        \"verb\": token.head.lemma_ if token.head.pos_ == 'VERB' else None,\n",
    "                        \"confidence\": 1.0 if token.dep_ in (\"nsubj\", \"dobj\") else 0.8\n",
    "                    })\n",
    "\n",
    "        return relationships, entities\n",
    "\n",
    "    def build_graph(self):\n",
    "        \"\"\"\n",
    "        Enhanced graph building with better entity handling.\n",
    "        \"\"\"\n",
    "        for _, row in self.data.iterrows():\n",
    "            incident_description = row.get(\"Incident_Description\", \"\")\n",
    "            relationships, entities = self.extract_entities_and_relationships(incident_description)\n",
    "\n",
    "            # Add entity nodes with more context\n",
    "            for entity, entity_type in entities:\n",
    "                if len(entity.split()) <= 3:  # Filter out overly long phrases\n",
    "                    self.graph.add_node(\n",
    "                        entity,\n",
    "                        type=entity_type,\n",
    "                        category=row.get(\"Contributing_Factor\", \"Unknown\"),\n",
    "                        context=row.get(\"Event_Context\", \"\")\n",
    "                    )\n",
    "\n",
    "            # Add relationship edges with enhanced information\n",
    "            for rel in relationships:\n",
    "                subject = rel[\"subject\"]\n",
    "                obj = rel[\"object\"]\n",
    "\n",
    "                # Skip very short or common words\n",
    "                if (len(subject) <= 2 or len(obj) <= 2 or\n",
    "                    subject.lower() in ['on', 'in', 'of'] or\n",
    "                    obj.lower() in ['on', 'in', 'of']):\n",
    "                    continue\n",
    "\n",
    "                # Add nodes if they don't exist\n",
    "                for node in [subject, obj]:\n",
    "                    if node not in self.graph:\n",
    "                        self.graph.add_node(\n",
    "                            node,\n",
    "                            type=\"Entity\",\n",
    "                            category=row.get(\"Contributing_Factor\", \"Unknown\"),\n",
    "                            context=row.get(\"Event_Context\", \"\")\n",
    "                        )\n",
    "\n",
    "                # Add edge with rich metadata\n",
    "                self.graph.add_edge(\n",
    "                    subject,\n",
    "                    obj,\n",
    "                    relationship=rel[\"relation\"],\n",
    "                    context=rel[\"context\"],\n",
    "                    confidence=rel.get(\"confidence\", 1.0),\n",
    "                    incident_type=row.get(\"Contributing_Factor\", \"Unknown\")\n",
    "                )\n",
    "\n",
    "        print(f\"Graph built successfully with {self.graph.number_of_nodes()} nodes and {self.graph.number_of_edges()} edges!\")\n",
    "\n",
    "    def detect_communities(self):\n",
    "        \"\"\"\n",
    "        Detect communities in the graph using Label Propagation.\n",
    "        \"\"\"\n",
    "        from networkx.algorithms.community import asyn_lpa_communities\n",
    "\n",
    "        # Convert to undirected graph for community detection\n",
    "        undirected_graph = self.graph.to_undirected()\n",
    "        self.communities = list(asyn_lpa_communities(undirected_graph))\n",
    "\n",
    "        # Assign community labels to nodes\n",
    "        community_mapping = {}\n",
    "        for i, community in enumerate(self.communities):\n",
    "            for node in community:\n",
    "                community_mapping[node] = i\n",
    "        nx.set_node_attributes(self.graph, community_mapping, 'community')\n",
    "\n",
    "        print(f\"Detected {len(self.communities)} communities!\")\n",
    "\n",
    "    def summarize_communities(self, openai_api_key):\n",
    "        \"\"\"\n",
    "        Summarize each community using OpenAI's ChatCompletion API.\n",
    "        \"\"\"\n",
    "        def summarize_community(community_nodes):\n",
    "            \"\"\"Summarize a single community.\"\"\"\n",
    "            context = \"This is a community of entities and their relationships:\\n\"\n",
    "\n",
    "            # Add nodes and their types\n",
    "            for node in community_nodes:\n",
    "                node_type = self.graph.nodes[node].get('type', 'Unknown')\n",
    "                context += f\"- {node} (Type: {node_type})\\n\"\n",
    "\n",
    "                # Add relationships for this node\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "                    edge_data = self.graph.get_edge_data(node, neighbor)\n",
    "                    if edge_data:\n",
    "                        relationship = edge_data.get('relationship', 'related_to')\n",
    "                        context += f\"  → {relationship} → {neighbor}\\n\"\n",
    "\n",
    "            client = OpenAI(api_key=openai_api_key)\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an assistant specializing in analyzing entity relationships in aviation safety incidents.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Analyze and summarize the following entity relationships, focusing on key patterns and insights:\\n{context}\"}\n",
    "                ],\n",
    "                max_tokens=300,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "\n",
    "        self.community_summaries = {}\n",
    "        for i, community in enumerate(self.communities):\n",
    "            try:\n",
    "                summary = summarize_community(community)\n",
    "                self.community_summaries[i] = summary\n",
    "                print(f\"Community {i} Summary:\\n{summary}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error summarizing community {i}: {e}\")\n",
    "\n",
    "    def get_graph_summary(self):\n",
    "        \"\"\"\n",
    "        Provide a detailed summary of the graph structure.\n",
    "        \"\"\"\n",
    "        summary = {\n",
    "            \"Total Nodes\": self.graph.number_of_nodes(),\n",
    "            \"Total Edges\": self.graph.number_of_edges(),\n",
    "            \"Communities Detected\": len(self.communities) if hasattr(self, \"communities\") else 0,\n",
    "            \"Node Types\": self._get_node_type_distribution(),\n",
    "            \"Relationship Types\": self._get_relationship_distribution(),\n",
    "            \"Average Degree\": sum(dict(self.graph.degree()).values()) / self.graph.number_of_nodes()\n",
    "        }\n",
    "        return summary\n",
    "\n",
    "    def _get_node_type_distribution(self):\n",
    "        \"\"\"Helper method to get distribution of node types.\"\"\"\n",
    "        type_count = {}\n",
    "        for node in self.graph.nodes():\n",
    "            node_type = self.graph.nodes[node].get('type', 'Unknown')\n",
    "            type_count[node_type] = type_count.get(node_type, 0) + 1\n",
    "        return type_count\n",
    "\n",
    "    def _get_relationship_distribution(self):\n",
    "        \"\"\"Helper method to get distribution of relationship types.\"\"\"\n",
    "        rel_count = {}\n",
    "        for _, _, data in self.graph.edges(data=True):\n",
    "            rel_type = data.get('relationship', 'Unknown')\n",
    "            rel_count[rel_type] = rel_count.get(rel_type, 0) + 1\n",
    "        return rel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Xx88G-BLMNc_",
   "metadata": {
    "id": "Xx88G-BLMNc_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def visualize_graph_with_communities(graph):\n",
    "    \"\"\"\n",
    "    Visualize the graph with nodes colored by their community.\n",
    "    \"\"\"\n",
    "    # Get community labels\n",
    "    communities = nx.get_node_attributes(graph, 'community')\n",
    "    if not communities:\n",
    "        print(\"No communities detected. Please run community detection first.\")\n",
    "        return\n",
    "\n",
    "    # Assign colors to communities\n",
    "    community_colors = {node: communities[node] for node in graph.nodes()}\n",
    "\n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(graph)  # Generate layout for visualization\n",
    "    nx.draw(\n",
    "        graph,\n",
    "        pos,\n",
    "        with_labels=True,\n",
    "        node_color=[community_colors.get(node, 0) for node in graph.nodes()],\n",
    "        cmap=plt.cm.rainbow,\n",
    "        node_size=500,\n",
    "        font_size=8,\n",
    "    )\n",
    "    plt.title(\"Graph Visualization with Communities\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8IcJOiRnU-AG",
   "metadata": {
    "id": "8IcJOiRnU-AG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "class GraphRetriever:\n",
    "    def __init__(self, graph, embedding_model=\"text-embedding-3-small\"):\n",
    "        \"\"\"\n",
    "        Initialize the graph retriever.\n",
    "\n",
    "        Args:\n",
    "            graph: The graph object containing nodes and edges.\n",
    "            embedding_model: Model to use for generating embeddings.\n",
    "        \"\"\"\n",
    "        self.graph = graph\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embeddings = {}\n",
    "        self.openai_client = None\n",
    "\n",
    "    def set_openai_client(self, api_key):\n",
    "        \"\"\"\n",
    "        Set up the OpenAI client.\n",
    "\n",
    "        Args:\n",
    "            api_key: OpenAI API key.\n",
    "        \"\"\"\n",
    "        self.openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        \"\"\"Generate embeddings with caching.\"\"\"\n",
    "        cache_file = \"embeddings_cache.json\"\n",
    "\n",
    "        # Load cache if exists\n",
    "        if os.path.exists(cache_file):\n",
    "            with open(cache_file, 'r') as f:\n",
    "                self.embeddings = json.load(f)\n",
    "\n",
    "        # Generate missing embeddings\n",
    "        new_nodes = set(self.graph.nodes()) - set(self.embeddings.keys())\n",
    "        if new_nodes:\n",
    "            for node in new_nodes:\n",
    "                # Generate embedding as before\n",
    "                node_text = f\"{node} ({self.graph.nodes[node].get('type', 'Unknown')})\"\n",
    "                response = self.openai_client.embeddings.create(\n",
    "                    model=self.embedding_model,\n",
    "                    input=node_text,\n",
    "                    encoding_format=\"float\"\n",
    "                )\n",
    "                self.embeddings[node] = response.data[0].embedding\n",
    "\n",
    "            # Save updated cache\n",
    "            with open(cache_file, 'w') as f:\n",
    "                json.dump(self.embeddings, f)\n",
    "\n",
    "    def calculate_similarity(self, query_embedding, node_embedding):\n",
    "        \"\"\"\n",
    "        Calculate cosine similarity between query and node embeddings.\n",
    "        \"\"\"\n",
    "        dot_product = np.dot(query_embedding, node_embedding)\n",
    "        query_norm = np.linalg.norm(query_embedding)\n",
    "        node_norm = np.linalg.norm(node_embedding)\n",
    "        return dot_product / (query_norm * node_norm)\n",
    "\n",
    "    def retrieve(self, query, k=5):\n",
    "        \"\"\"\n",
    "        Retrieve k most relevant nodes based on the query.\n",
    "\n",
    "        Args:\n",
    "            query: The search query.\n",
    "            k: Number of nodes to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            List of (node, similarity_score) tuples.\n",
    "        \"\"\"\n",
    "        if not self.embeddings:\n",
    "            raise ValueError(\"No embeddings generated. Call generate_embeddings first.\")\n",
    "\n",
    "        # Generate embedding for the query\n",
    "        query_response = self.openai_client.embeddings.create(\n",
    "            model=self.embedding_model,\n",
    "            input=query,\n",
    "            encoding_format=\"float\"\n",
    "        )\n",
    "        query_embedding = query_response.data[0].embedding\n",
    "\n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for node, node_embedding in self.embeddings.items():\n",
    "            similarity = self.calculate_similarity(query_embedding, node_embedding)\n",
    "            similarities.append((node, similarity))\n",
    "\n",
    "        # Sort by similarity and return top k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similarities[:k]\n",
    "\n",
    "    def retrieve_with_context(self, query, k=5, include_neighbors=True):\n",
    "        \"\"\"\n",
    "        Retrieve relevant nodes with their neighborhood context.\n",
    "\n",
    "        Args:\n",
    "            query: The search query.\n",
    "            k: Number of nodes to retrieve.\n",
    "            include_neighbors: Whether to include neighboring nodes.\n",
    "\n",
    "        Returns:\n",
    "            Dictionary with relevant nodes and their context.\n",
    "        \"\"\"\n",
    "        relevant_nodes = self.retrieve(query, k)\n",
    "\n",
    "        results = {}\n",
    "        for node, score in relevant_nodes:\n",
    "            context = {\n",
    "                'similarity_score': score,\n",
    "                'node_type': self.graph.nodes[node].get('type', 'Unknown'),\n",
    "                'neighbors': [],\n",
    "                'edges': []\n",
    "            }\n",
    "\n",
    "            if include_neighbors:\n",
    "                # Get neighboring nodes\n",
    "                neighbors = list(self.graph.neighbors(node))\n",
    "                neighbor_data = []\n",
    "                for neighbor in neighbors:\n",
    "                    neighbor_data.append({\n",
    "                        'node': neighbor,\n",
    "                        'type': self.graph.nodes[neighbor].get('type', 'Unknown')\n",
    "                    })\n",
    "                context['neighbors'] = neighbor_data\n",
    "\n",
    "                # Get edges with these neighbors\n",
    "                edges = []\n",
    "                for neighbor in neighbors:\n",
    "                    edge_data = self.graph.get_edge_data(node, neighbor)\n",
    "                    if edge_data:\n",
    "                        edges.append({\n",
    "                            'source': node,\n",
    "                            'target': neighbor,\n",
    "                            'attributes': edge_data\n",
    "                        })\n",
    "                context['edges'] = edges\n",
    "\n",
    "            results[node] = context\n",
    "\n",
    "        return results\n",
    "\n",
    "    def search(self, query, k=5, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Search the graph with a semantic query.\n",
    "\n",
    "        Args:\n",
    "            query: Search query.\n",
    "            k: Maximum number of results to return.\n",
    "            threshold: Minimum similarity score threshold.\n",
    "\n",
    "        Returns:\n",
    "            List of relevant results with context.\n",
    "        \"\"\"\n",
    "        results = self.retrieve_with_context(query, k)\n",
    "\n",
    "        # Filter by threshold\n",
    "        filtered_results = {\n",
    "            node: data\n",
    "            for node, data in results.items()\n",
    "            if data['similarity_score'] >= threshold\n",
    "        }\n",
    "\n",
    "        return filtered_results\n",
    "    def hybrid_search(self, query, k=5, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Combine semantic and structural search.\n",
    "\n",
    "        Args:\n",
    "            query: Search query\n",
    "            k: Number of results\n",
    "            alpha: Weight between semantic (0) and structural (1) similarity\n",
    "        \"\"\"\n",
    "        semantic_results = self.search(query, k=k)\n",
    "\n",
    "        # Add PageRank scores for structural importance\n",
    "        pagerank_scores = nx.pagerank(self.graph)\n",
    "\n",
    "        # Combine scores\n",
    "        combined_results = {}\n",
    "        for node, data in semantic_results.items():\n",
    "            combined_score = (\n",
    "                alpha * pagerank_scores[node] +\n",
    "                (1 - alpha) * data['similarity_score']\n",
    "            )\n",
    "            data['combined_score'] = combined_score\n",
    "            combined_results[node] = data\n",
    "\n",
    "        return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Ugaly1qT0e2T",
   "metadata": {
    "id": "Ugaly1qT0e2T"
   },
   "outputs": [],
   "source": [
    "# Pipeline integration code\n",
    "def run_analysis_pipeline(csv_path, openai_api_key, cache_dir=\"cache\"):\n",
    "    \"\"\"\n",
    "    Run the complete analysis pipeline with enhanced features.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to the FAA data CSV\n",
    "        openai_api_key: OpenAI API key\n",
    "        cache_dir: Directory for caching (reserved for future use)\n",
    "    \"\"\"\n",
    "    # Create cache directory if it doesn't exist\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Data Preparation\n",
    "    print(\"Step 1: Preparing data...\")\n",
    "    data_preparer = DataPreparer(csv_path)\n",
    "    data_preparer.load_data()\n",
    "    data_preparer.clean_data()\n",
    "    data_preparer.normalize_text()\n",
    "    prepared_data = data_preparer.get_prepared_data()\n",
    "\n",
    "    # Step 2: Graph Processing\n",
    "    print(\"\\nStep 2: Building and processing graph...\")\n",
    "    graph_processor = DynamicGraphProcessor(prepared_data)\n",
    "    graph_processor.build_graph()\n",
    "\n",
    "    # Step 3: Community Detection\n",
    "    print(\"\\nStep 3: Detecting communities...\")\n",
    "    graph_processor.detect_communities()\n",
    "\n",
    "    # Step 4: Set up retriever\n",
    "    print(\"\\nStep 4: Setting up retriever and generating embeddings...\")\n",
    "    retriever = GraphRetriever(\n",
    "        graph_processor.graph,\n",
    "        embedding_model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    retriever.set_openai_client(openai_api_key)\n",
    "    retriever.generate_embeddings()\n",
    "\n",
    "    return {\n",
    "        'data_preparer': data_preparer,\n",
    "        'graph_processor': graph_processor,\n",
    "        'retriever': retriever\n",
    "    }\n",
    "\n",
    "def query_graph(retriever, query, k=10, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Query the graph and generate a coherent summary answer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Executing search...\")\n",
    "        results = retriever.search(query, k=k, threshold=threshold)\n",
    "\n",
    "        if not results:\n",
    "            return \"No relevant information found in the incident data.\"\n",
    "\n",
    "        # Collect and analyze the findings\n",
    "        findings = {\n",
    "            'incidents': [],\n",
    "            'categories': set(),\n",
    "            'contexts': set(),\n",
    "            'relationships': []\n",
    "        }\n",
    "\n",
    "        for node, data in results.items():\n",
    "            node_attrs = retriever.graph.nodes[node]\n",
    "\n",
    "            # Collect incident categories\n",
    "            if 'category' in node_attrs:\n",
    "                findings['categories'].add(node_attrs['category'])\n",
    "\n",
    "            # Collect contexts\n",
    "            if 'context' in node_attrs:\n",
    "                findings['contexts'].add(node_attrs['context'])\n",
    "\n",
    "            # Collect relationships and their contexts\n",
    "            if data.get('edges'):\n",
    "                for edge in data['edges']:\n",
    "                    attrs = edge.get('attributes', {})\n",
    "                    if 'context' in attrs:\n",
    "                        findings['relationships'].append({\n",
    "                            'source': edge['source'],\n",
    "                            'target': edge['target'],\n",
    "                            'context': attrs['context']\n",
    "                        })\n",
    "\n",
    "        # Generate a coherent summary\n",
    "        client = OpenAI(api_key=retriever.openai_client.api_key)\n",
    "\n",
    "        # Prepare the context for GPT\n",
    "        context = f\"\"\"\n",
    "Based on the analysis of aviation incident data:\n",
    "\n",
    "Categories of incidents: {', '.join(findings['categories'])}\n",
    "Incident contexts: {', '.join(findings['contexts'])}\n",
    "\n",
    "Key relationships found:\n",
    "{chr(10).join([f\"- {r['source']} related to {r['target']}: {r['context']}\" for r in findings['relationships']])}\n",
    "\n",
    "Original query: {query}\n",
    "\"\"\"\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an aviation safety analyst. Provide a clear, concise summary of incident data findings.\"},\n",
    "                {\"role\": \"user\", \"content\": context}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        summary = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Print detailed findings for reference\n",
    "        print(\"\\nDetailed Findings:\")\n",
    "        print(\"=\"*50)\n",
    "        for node, data in results.items():\n",
    "            print(f\"\\nNode: {node}\")\n",
    "            print(f\"Similarity Score: {data['similarity_score']:.3f}\")\n",
    "            print(f\"Node Type: {data['node_type']}\")\n",
    "            if data.get('neighbors'):\n",
    "                print(\"\\nRelated factors:\")\n",
    "                for neighbor in data['neighbors']:\n",
    "                    print(f\"- {neighbor['node']}\")\n",
    "\n",
    "        print(\"\\nSummary Answer:\")\n",
    "        print(\"=\"*50)\n",
    "        print(summary)\n",
    "\n",
    "        return summary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during query: {e}\")\n",
    "        return f\"Error processing query: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "BgDGSDqW0mtl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgDGSDqW0mtl",
    "outputId": "a9637cdd-1a41-4857-ca76-2d2b413379ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing data...\n",
      "Data loaded successfully!\n",
      "Data cleaned successfully!\n",
      "Text fields normalized successfully!\n",
      "\n",
      "Step 2: Building and processing graph...\n",
      "Graph built successfully with 488 nodes and 468 edges!\n",
      "\n",
      "Step 3: Detecting communities...\n",
      "Detected 184 communities!\n",
      "\n",
      "Step 4: Setting up retriever and generating embeddings...\n",
      "\n",
      "Pipeline Statistics:\n",
      "------------------------------\n",
      "Total nodes in graph: 488\n",
      "Total edges in graph: 468\n",
      "Number of embeddings generated: 488\n",
      "\n",
      "Graph Analysis:\n",
      "------------------------------\n",
      "Most connected nodes:\n",
      "- engine: 23 connections\n",
      "- pilot: 23 connections\n",
      "- aircraft: 18 connections\n",
      "- fuel: 15 connections\n",
      "- flight: 15 connections\n",
      "\n",
      "Executing Query: What is the most common cause of engine failure?\n",
      "--------------------------------------------------\n",
      "Executing search...\n",
      "Found 3 relevant results:\n",
      "\n",
      "==================================================\n",
      "Node: engine\n",
      "Similarity Score: 0.384\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 4\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Compound Relationships:\n",
      "- takeoff (Entity) | Confidence: 0.80\n",
      "  Context: takeoff engine\n",
      "- climb (Entity) | Confidence: 0.80\n",
      "  Context: climb aircraft engine\n",
      "- aircraft (Entity) | Confidence: 0.80\n",
      "  Context: aircraft engine\n",
      "- nr2 (Entity) | Confidence: 0.80\n",
      "  Context: nr2 engine\n",
      "- climbout (Entity) | Confidence: 0.80\n",
      "  Context: climbout engine\n",
      "- stall (Entity) | Confidence: 0.80\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "- nr1 (Entity) | Confidence: 0.80\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "\n",
      "Amod Relationships:\n",
      "- left (Entity) | Confidence: 0.80\n",
      "  Context: left engine near h71 feathered high  \n",
      "- rough (Entity) | Confidence: 0.80\n",
      "  Context: rough engine climbout\n",
      "- rolled (Entity) | Confidence: 0.80\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "\n",
      "Relationships:\n",
      "- engine → compound → takeoff\n",
      "  Context: takeoff engine\n",
      "- engine → compound → climb\n",
      "  Context: climb aircraft engine\n",
      "- engine → compound → aircraft\n",
      "  Context: aircraft engine\n",
      "- engine → compound → nr2\n",
      "  Context: nr2 engine\n",
      "- engine → amod → left\n",
      "  Context: left engine near h71 feathered high  \n",
      "- engine → amod → rough\n",
      "  Context: rough engine climbout\n",
      "- engine → compound → climbout\n",
      "  Context: climbout engine\n",
      "- engine → amod → rolled\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "- engine → compound → stall\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "- engine → compound → nr1\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: failure\n",
      "Similarity Score: 0.317\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 72\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Compound Relationships:\n",
      "- power (Entity) | Confidence: 0.80\n",
      "  Context: engine power failure aerobatics landed field pilot\n",
      "- engine (Entity) | Confidence: 0.80\n",
      "  Context: engine failure takeoff aircraft\n",
      "\n",
      "Relationships:\n",
      "- failure → compound → power\n",
      "  Context: engine power failure aerobatics landed field pilot\n",
      "- failure → compound → engine\n",
      "  Context: engine failure takeoff aircraft\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: overheat\n",
      "Similarity Score: 0.311\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 60\n",
      "==================================================\n",
      "\n",
      "Analysis Summary:\n",
      "------------------------------\n",
      "\n",
      "Incident Categories:\n",
      "- inadequate insp of a: 3 occurrences\n",
      "\n",
      "Key Relationship Patterns:\n",
      "- compound: rolled compressor stall nr1 engine (2 occurrences)\n",
      "- compound: takeoff engine (1 occurrences)\n",
      "- compound: climb aircraft engine (1 occurrences)\n",
      "- compound: aircraft engine (1 occurrences)\n",
      "- compound: nr2 engine (1 occurrences)\n",
      "\n",
      "\n",
      "\n",
      "Executing Query: Describe incidents involving engine problems\n",
      "--------------------------------------------------\n",
      "Executing search...\n",
      "Found 8 relevant results:\n",
      "\n",
      "==================================================\n",
      "Node: engine\n",
      "Similarity Score: 0.430\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 4\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Compound Relationships:\n",
      "- takeoff (Entity) | Confidence: 0.80\n",
      "  Context: takeoff engine\n",
      "- climb (Entity) | Confidence: 0.80\n",
      "  Context: climb aircraft engine\n",
      "- aircraft (Entity) | Confidence: 0.80\n",
      "  Context: aircraft engine\n",
      "- nr2 (Entity) | Confidence: 0.80\n",
      "  Context: nr2 engine\n",
      "- climbout (Entity) | Confidence: 0.80\n",
      "  Context: climbout engine\n",
      "- stall (Entity) | Confidence: 0.80\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "- nr1 (Entity) | Confidence: 0.80\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "\n",
      "Amod Relationships:\n",
      "- left (Entity) | Confidence: 0.80\n",
      "  Context: left engine near h71 feathered high  \n",
      "- rough (Entity) | Confidence: 0.80\n",
      "  Context: rough engine climbout\n",
      "- rolled (Entity) | Confidence: 0.80\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "\n",
      "Relationships:\n",
      "- engine → compound → takeoff\n",
      "  Context: takeoff engine\n",
      "- engine → compound → climb\n",
      "  Context: climb aircraft engine\n",
      "- engine → compound → aircraft\n",
      "  Context: aircraft engine\n",
      "- engine → compound → nr2\n",
      "  Context: nr2 engine\n",
      "- engine → amod → left\n",
      "  Context: left engine near h71 feathered high  \n",
      "- engine → amod → rough\n",
      "  Context: rough engine climbout\n",
      "- engine → compound → climbout\n",
      "  Context: climbout engine\n",
      "- engine → amod → rolled\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "- engine → compound → stall\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "- engine → compound → nr1\n",
      "  Context: rolled compressor stall nr1 engine\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: crashed\n",
      "Similarity Score: 0.350\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: attempt operation wi\n",
      "- context: emergency landing\n",
      "- community: 106\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Dobj Relationships:\n",
      "- pins (Entity) | Confidence: 1.00\n",
      "  Context: crashed locking pins seat track seat pin bent belt\n",
      "\n",
      "Relationships:\n",
      "- crashed → dobj → pins\n",
      "  Context: crashed locking pins seat track seat pin bent belt\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: crash\n",
      "Similarity Score: 0.328\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 112\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Amod Relationships:\n",
      "- initial (Entity) | Confidence: 0.80\n",
      "  Context: initial climbout crash\n",
      "\n",
      "Compound Relationships:\n",
      "- climbout (Entity) | Confidence: 0.80\n",
      "  Context: initial climbout crash\n",
      "\n",
      "Relationships:\n",
      "- crash → amod → initial\n",
      "  Context: initial climbout crash\n",
      "- crash → compound → climbout\n",
      "  Context: initial climbout crash\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: problems\n",
      "Similarity Score: 0.328\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: attempt operation wi\n",
      "- context: othermiscellaneous\n",
      "- community: 30\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Compound Relationships:\n",
      "- brake (Entity) | Confidence: 0.80\n",
      "  Context: brake problems aircraft\n",
      "\n",
      "Relationships:\n",
      "- problems → compound → brake\n",
      "  Context: brake problems aircraft\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: emergency\n",
      "Similarity Score: 0.317\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 23\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: fuel\n",
      "Similarity Score: 0.315\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 8\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Amod Relationships:\n",
      "- secured (Entity) | Confidence: 0.80\n",
      "  Context: secured fuel siphoned\n",
      "\n",
      "Relationships:\n",
      "- fuel → amod → secured\n",
      "  Context: secured fuel siphoned\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: overheat\n",
      "Similarity Score: 0.314\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 60\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: failure\n",
      "Similarity Score: 0.314\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 72\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Compound Relationships:\n",
      "- power (Entity) | Confidence: 0.80\n",
      "  Context: engine power failure aerobatics landed field pilot\n",
      "- engine (Entity) | Confidence: 0.80\n",
      "  Context: engine failure takeoff aircraft\n",
      "\n",
      "Relationships:\n",
      "- failure → compound → power\n",
      "  Context: engine power failure aerobatics landed field pilot\n",
      "- failure → compound → engine\n",
      "  Context: engine failure takeoff aircraft\n",
      "==================================================\n",
      "\n",
      "Analysis Summary:\n",
      "------------------------------\n",
      "\n",
      "Incident Categories:\n",
      "- inadequate insp of a: 6 occurrences\n",
      "- attempt operation wi: 2 occurrences\n",
      "\n",
      "Key Relationship Patterns:\n",
      "- compound: rolled compressor stall nr1 engine (2 occurrences)\n",
      "- compound: takeoff engine (1 occurrences)\n",
      "- compound: climb aircraft engine (1 occurrences)\n",
      "- compound: aircraft engine (1 occurrences)\n",
      "- compound: nr2 engine (1 occurrences)\n",
      "\n",
      "\n",
      "\n",
      "Executing Query: How do weather conditions affect incidents?\n",
      "--------------------------------------------------\n",
      "Executing search...\n",
      "No results found above the similarity threshold.\n",
      "Found results with relaxed threshold.\n",
      "\n",
      "\n",
      "\n",
      "Executing Query: What are the main factors in landing incidents?\n",
      "--------------------------------------------------\n",
      "Executing search...\n",
      "Found 2 relevant results:\n",
      "\n",
      "==================================================\n",
      "Node: landing\n",
      "Similarity Score: 0.397\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 23\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Amod Relationships:\n",
      "- forced (Entity) | Confidence: 0.80\n",
      "  Context: forced landing\n",
      "\n",
      "Compound Relationships:\n",
      "- airport (Entity) | Confidence: 0.80\n",
      "  Context: airport landing near blo\n",
      "- emergency (Entity) | Confidence: 0.80\n",
      "  Context: emergency landing\n",
      "- nose (Entity) | Confidence: 0.80\n",
      "  Context: nose landing\n",
      "\n",
      "Relationships:\n",
      "- landing → amod → forced\n",
      "  Context: forced landing\n",
      "- landing → compound → airport\n",
      "  Context: airport landing near blo\n",
      "- landing → compound → emergency\n",
      "  Context: emergency landing\n",
      "- landing → compound → nose\n",
      "  Context: nose landing\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: landed\n",
      "Similarity Score: 0.314\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: emergency landing\n",
      "- community: 35\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Nsubj Relationships:\n",
      "- umc (Entity) | Confidence: 1.00\n",
      "  Context: belwo umc landed sea ice\n",
      "- engine (Entity) | Confidence: 1.00\n",
      "  Context: rough engine climbout landed city street spark plugs tolerence found primer unlocked\n",
      "- pilot (Entity) | Confidence: 1.00\n",
      "  Context: rough pilot landed field claims water fuel\n",
      "- power (Entity) | Confidence: 1.00\n",
      "  Context: lost power en route landed private strip nosed left fuel cap leaked prevented gravity fuel flow\n",
      "\n",
      "Relationships:\n",
      "- landed → nsubj → umc\n",
      "  Context: belwo umc landed sea ice\n",
      "- landed → nsubj → engine\n",
      "  Context: rough engine climbout landed city street spark plugs tolerence found primer unlocked\n",
      "- landed → nsubj → pilot\n",
      "  Context: rough pilot landed field claims water fuel\n",
      "- landed → nsubj → power\n",
      "  Context: lost power en route landed private strip nosed left fuel cap leaked prevented gravity fuel flow\n",
      "==================================================\n",
      "\n",
      "Analysis Summary:\n",
      "------------------------------\n",
      "\n",
      "Incident Categories:\n",
      "- inadequate insp of a: 2 occurrences\n",
      "\n",
      "Key Relationship Patterns:\n",
      "- amod: forced landing (1 occurrences)\n",
      "- compound: airport landing near blo (1 occurrences)\n",
      "- compound: emergency landing (1 occurrences)\n",
      "- compound: nose landing (1 occurrences)\n",
      "- nsubj: belwo umc landed sea ice (1 occurrences)\n",
      "\n",
      "\n",
      "\n",
      "Executing Query: What types of pilot errors are reported?\n",
      "--------------------------------------------------\n",
      "Executing search...\n",
      "Found 2 relevant results:\n",
      "\n",
      "==================================================\n",
      "Node: pilot\n",
      "Similarity Score: 0.509\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: attempt operation wi\n",
      "- context: weather\n",
      "- community: 26\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Amod Relationships:\n",
      "- unable (Entity) | Confidence: 0.80\n",
      "  Context: pilot unable pressurize\n",
      "- rough (Entity) | Confidence: 0.80\n",
      "  Context: rough pilot\n",
      "\n",
      "Compound Relationships:\n",
      "- field (Entity) | Confidence: 0.80\n",
      "  Context: field pilot\n",
      "- atc (Entity) | Confidence: 0.80\n",
      "  Context: atc communication pilot\n",
      "- communication (Entity) | Confidence: 0.80\n",
      "  Context: atc communication pilot\n",
      "- altitude (Entity) | Confidence: 0.80\n",
      "  Context: altitude pilot\n",
      "- pilot (Entity) | Confidence: 0.80\n",
      "  Context: pilot pilot\n",
      "\n",
      "Relationships:\n",
      "- pilot → amod → unable\n",
      "  Context: pilot unable pressurize\n",
      "- pilot → compound → field\n",
      "  Context: field pilot\n",
      "- pilot → compound → atc\n",
      "  Context: atc communication pilot\n",
      "- pilot → compound → communication\n",
      "  Context: atc communication pilot\n",
      "- pilot → compound → altitude\n",
      "  Context: altitude pilot\n",
      "- pilot → amod → rough\n",
      "  Context: rough pilot\n",
      "- pilot → compound → pilot\n",
      "  Context: pilot pilot\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "Node: pilots\n",
      "Similarity Score: 0.498\n",
      "Node Type: Entity\n",
      "\n",
      "Node Attributes:\n",
      "- category: inadequate insp of a\n",
      "- context: othermiscellaneous\n",
      "- community: 100\n",
      "\n",
      "Neighboring Nodes:\n",
      "\n",
      "Compound Relationships:\n",
      "- roll (Entity) | Confidence: 0.80\n",
      "  Context: takeoff roll pilots\n",
      "\n",
      "Relationships:\n",
      "- pilots → compound → roll\n",
      "  Context: takeoff roll pilots\n",
      "==================================================\n",
      "\n",
      "Analysis Summary:\n",
      "------------------------------\n",
      "\n",
      "Incident Categories:\n",
      "- attempt operation wi: 1 occurrences\n",
      "- inadequate insp of a: 1 occurrences\n",
      "\n",
      "Key Relationship Patterns:\n",
      "- compound: atc communication pilot (2 occurrences)\n",
      "- amod: pilot unable pressurize (1 occurrences)\n",
      "- compound: field pilot (1 occurrences)\n",
      "- compound: altitude pilot (1 occurrences)\n",
      "- amod: rough pilot (1 occurrences)\n",
      "\n",
      "\n",
      "\n",
      "Executing Query: What safety issues are most common?\n",
      "--------------------------------------------------\n",
      "Executing search...\n",
      "No results found above the similarity threshold.\n",
      "Found results with relaxed threshold.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the main execution part:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the pipeline\n",
    "    pipeline_results = run_analysis_pipeline(\n",
    "        csv_path=\"FAA_sample_100.csv\",\n",
    "        openai_api_key=openai_api_key,\n",
    "        cache_dir=\"graph_cache\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nPipeline Statistics:\")\n",
    "    print(\"-\"*30)\n",
    "    retriever = pipeline_results['retriever']\n",
    "    graph_processor = pipeline_results['graph_processor']\n",
    "    print(f\"Total nodes in graph: {graph_processor.graph.number_of_nodes()}\")\n",
    "    print(f\"Total edges in graph: {graph_processor.graph.number_of_edges()}\")\n",
    "    print(f\"Number of embeddings generated: {len(retriever.embeddings)}\")\n",
    "\n",
    "    # Add graph analysis\n",
    "    print(\"\\nGraph Analysis:\")\n",
    "    print(\"-\"*30)\n",
    "    print(\"Most connected nodes:\")\n",
    "    degrees = sorted([(n, d) for n, d in graph_processor.graph.degree()],\n",
    "                    key=lambda x: x[1], reverse=True)[:5]\n",
    "    for node, degree in degrees:\n",
    "        print(f\"- {node}: {degree} connections\")\n",
    "\n",
    "    # Run example queries with more variation\n",
    "    queries = [\n",
    "        \"What is the most common cause of engine failure?\",\n",
    "        \"Describe incidents involving engine problems\",\n",
    "        \"How do weather conditions affect incidents?\",\n",
    "        \"What are the main factors in landing incidents?\",\n",
    "        \"What types of pilot errors are reported?\",\n",
    "        \"What safety issues are most common?\"\n",
    "    ]\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"\\nExecuting Query: {query}\")\n",
    "        print(\"-\"*50)\n",
    "        results = query_graph(\n",
    "            pipeline_results['retriever'],\n",
    "            query,\n",
    "            k=8,  # Increased number of results\n",
    "            threshold=0.3  # Lowered threshold\n",
    "        )\n",
    "\n",
    "        if not results:\n",
    "            print(\"No results found for this query.\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bqc3PRpG8ZUR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqc3PRpG8ZUR",
    "outputId": "25cd781a-4149-42cb-9bde-d735e6bcc496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing search...\n",
      "\n",
      "Detailed Findings:\n",
      "==================================================\n",
      "\n",
      "Node: engine\n",
      "Similarity Score: 0.384\n",
      "Node Type: Entity\n",
      "\n",
      "Related factors:\n",
      "- takeoff\n",
      "- climb\n",
      "- aircraft\n",
      "- nr2\n",
      "- left\n",
      "- rough\n",
      "- climbout\n",
      "- rolled\n",
      "- stall\n",
      "- nr1\n",
      "\n",
      "Node: failure\n",
      "Similarity Score: 0.317\n",
      "Node Type: Entity\n",
      "\n",
      "Related factors:\n",
      "- power\n",
      "- engine\n",
      "\n",
      "Node: overheat\n",
      "Similarity Score: 0.311\n",
      "Node Type: Entity\n",
      "\n",
      "Summary Answer:\n",
      "==================================================\n",
      "Based on the analysis of aviation incident data, the most common cause of engine failure is related to engine issues during takeoff and climbout phases of the flight. Engine failures were also associated with emergency landings and power failures during aerobatics. The data highlighted instances of engine-related problems such as rough engine operation, compressor stall, and power loss leading to emergency situations and forced landings. These findings emphasize the critical importance of proper engine maintenance and pre-flight inspections to ensure aviation safety.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"What is the most common cause of engine failure?\"\n",
    "summary = query_graph(retriever, query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
