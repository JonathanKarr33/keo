{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "104772e0-8f80-4818-b06d-f432f3038529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: nltk in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: sklearn_crfsuite in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (from scikit-learn==1.5.0) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (from scikit-learn==1.5.0) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.5.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (from scikit-learn==1.5.0) (3.5.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in /afs/crc.nd.edu/user/k/kmealey2/.local/lib/python3.11/site-packages (from sklearn_crfsuite) (0.9.10)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /opt/anaconda3/lib/python3.11/site-packages (from sklearn_crfsuite) (0.8.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.5.0 nltk sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fa0eff4-fc5e-4b00-8463-c022ab0477c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./NER-Evaluation\")\n",
    "\n",
    "import nltk\n",
    "import sklearn_crfsuite\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "\n",
    "from ner_evaluation.ner_eval import compute_metrics\n",
    "from ner_evaluation.ner_eval import compute_precision_recall_wrapper\n",
    "from ner_evaluation.ner_eval import find_overlap\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88818303-49d6-4d19-8e33-e5563fb8baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1a532-d253-4fd4-91ea-6dfe9c41ca01",
   "metadata": {},
   "source": [
    "### Implement our own version of collect_named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd180a8b-db8e-41c2-959f-3fd51bfd9177",
   "metadata": {},
   "source": [
    "**Use code from coref_reformat.ipynb from crosslingual_coref**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2549ef-33ca-46c9-a9ad-6abd9c2632e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FAA data in format {c5_id:{0: word0, 1: word1, ..., n: wordn}} using word tokenization from faa.conll\n",
    "\n",
    "faa = {}\n",
    "\n",
    "with open('../../data/FAA_data/faa.conll') as f:\n",
    "    text = f.read()\n",
    "\n",
    "docs = text.split('#begin document ')\n",
    "\n",
    "for doc in docs:\n",
    "    if doc[:5] == '(faa/':\n",
    "        word_count = 0\n",
    "        c5_id = doc.split('_')[1][:15]\n",
    "        faa[c5_id] = {}\n",
    "        lines = doc.split('\\n')\n",
    "        for line in lines[1:]:\n",
    "            if 'faa' in line:\n",
    "                faa[c5_id][word_count] = line.split()[3].upper()\n",
    "                word_count = word_count + 1\n",
    "# Fix known err\n",
    "faa['19980620030289I'] = {0: 'MR.', 1: 'KADERA', 2: 'THEN', 3: 'ATTEMPTED', 4: 'TO', 5: 'LAND', 6: 'IN', 7: 'A', 8: 'FIELD', 9: 'BUT', 10: 'WAS', 11: 'FORCED', 12: 'TO', 13: 'LAND', 14: 'ON', 15: 'HIGHWAY', 16: '93', 17: '.', 18: 'THREE', 19: 'MILES', 20: 'EAST', 21: 'OF', 22: 'SUNMER', 23: ',', 24: 'IOWA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396f935f-be04-412d-aced-d9aea0c35f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['MR.', 'KADERA', 'THEN', 'ATTEMPTED', 'TO', 'LAND', 'IN', 'A', 'FIELD', 'BUT', 'WAS', 'FORCED', 'TO', 'LAND', 'ON', 'HIGHWAY', '93', '.', 'THREE', 'MILES', 'EAST', 'OF', 'SUNMER', ',', 'IOWA'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faa['19980620030289I'].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eb28d157-c29e-4eac-b663-4c358ef1bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(mentions, words):\n",
    "    ''' Input:\n",
    "    - mentions:['MENTION1','MENTION2',...]\n",
    "    - words: ['This','is','a','sentence','.','This','is','another','sentence','.'] (dict values)\n",
    "        Output: [[startidx_mention1, end_idxmention1], [startidx_mention2, end_idxmention2], ...]\n",
    "    '''\n",
    "\n",
    "    mention_spans = []\n",
    "\n",
    "    if \"'S\" in words.values():\n",
    "        idx = list(words.values()).index(\"'S\")\n",
    "        words[idx-1] = words[idx-1] + \"'S\"\n",
    "        del words[idx]\n",
    "    \n",
    "    for imention, mention in enumerate(mentions):\n",
    "\n",
    "        mention = mention.replace('(', ' ( ').replace(')',' ) ').replace('  ',' ')\n",
    "        mention = mention.replace(',',' , ').replace('  ',' ')\n",
    "\n",
    "        mention_span = [-1, -1]\n",
    "\n",
    "        # if this mention has shown up before, find its end_idx in mention_spans\n",
    "        # ilastmntn (index of last mention) will be -1 if not found, or the index in mention_spans of the last one if found\n",
    "        ilastmntn = -1\n",
    "        keep_going = True\n",
    "        while keep_going:\n",
    "            try:\n",
    "                ilastmntn = mentions[ilastmntn+1:imention].index(mention)\n",
    "            except:\n",
    "                keep_going=False\n",
    "\n",
    "        # create lists of words and indices\n",
    "        # check_idxs maintains original token indices of words (doesn't always correspond to place in word if list if list is a slice or words have been removed)\n",
    "        check_words = list(words.values())\n",
    "        check_idxs = list(words.keys())\n",
    "        if ilastmntn > 0:\n",
    "            prev_idx = mention_spans[ilastmntn][1]\n",
    "            check_words = check_words[prev_idx:]\n",
    "            check_idxs = check_idxs[prev_idx:]\n",
    "\n",
    "        # loop through to find start and end indices of mention\n",
    "        # finds index of first word and then index of last word\n",
    "        # if we're looking for 'cargo door' and 'cargo' by itself appears previously in the sentence, it loop until it finds cargo door, not 'cargo xyzwkladsjfkl cargo door'\n",
    "        # doesn't account for case in which end word of mention occurs in the middle of the mention as well\n",
    "        start_idx = -1\n",
    "        end_idx = -1\n",
    "        marker = 0\n",
    "        prev_marker = -1\n",
    "        if mention in ' '.join(check_words):\n",
    "            while mention != ' '.join(check_words[start_idx:end_idx+1]) and marker != prev_marker:\n",
    "                try:\n",
    "                    start_idx = check_words[marker:].index(mention.split()[0])\n",
    "                    end_idx = check_words[start_idx:].index(mention.split()[-1]) + start_idx                \n",
    "                    mention_span = [check_idxs[start_idx], check_idxs[end_idx]+1]\n",
    "                except:\n",
    "                    break\n",
    "                prev_marker = marker\n",
    "                marker = start_idx + 1\n",
    "        \n",
    "        mention_spans.append(mention_span)\n",
    "\n",
    "    return mention_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ef6226b0-2aa6-4f0d-b6de-459e6e8e06b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(mentions, words):\n",
    "    ''' Input:\n",
    "    - mentions:['MENTION1','MENTION2',...]\n",
    "    - words: ['This','is','a','sentence','.','This','is','another','sentence','.'] (dict values)\n",
    "        Output: [[startidx_mention1, end_idxmention1], [startidx_mention2, end_idxmention2], ...]\n",
    "    '''\n",
    "\n",
    "    mention_spans = []\n",
    "\n",
    "    repeat_mentions = {}\n",
    "\n",
    "    if \"'S\" in words.values():\n",
    "        idx = list(words.values()).index(\"'S\")\n",
    "        words[idx-1] = words[idx-1] + \"'S\"\n",
    "        del words[idx]\n",
    "    \n",
    "    for imention, mention in enumerate(mentions):\n",
    "\n",
    "        mention = mention.replace('(', ' ( ').replace(')',' ) ').replace('  ',' ')\n",
    "        mention = mention.replace(',',' , ').replace('  ',' ')\n",
    "\n",
    "        mention_span = [-1, -1] # if conditions below aren't met, [-1,-1 is returned]\n",
    "\n",
    "        tokens = list(words.values())\n",
    "        idxs = list(words.keys())\n",
    "\n",
    "        # Check if mention has been seen before. If has, start_idx already stored in repeat_mentions\n",
    "        # Matched sequentially \n",
    "        if mention in repeat_mentions:\n",
    "            if len(repeat_mentions[mention]) > 0:\n",
    "                start_idx = repeat_mentions[mention].pop(0) # get start_idx and pop off list\n",
    "                end_idx = start_idx + len(mention.split()) - 1\n",
    "                mention_span = [idxs[start_idx],idxs[end_idx]+1]\n",
    "\n",
    "        # Normal case, where it has not been seen before, and we search for the start of the phrase in check_words\n",
    "        else:\n",
    "            start_indices = [i for i in range(len(tokens)) if tokens[i:i+len(mention.split())] == mention.split()]\n",
    "\n",
    "            # If start_indices contains multiple idxs, get start_idx from front of list (first occurance) and save rest to repeat_mentions\n",
    "            # If start_indices contains just one idx, that is the start_idx\n",
    "            if len(start_indices) > 0:\n",
    "                \n",
    "                if len(start_indices) > 1:\n",
    "                    repeat_mentions[mention] = start_indices[1:]\n",
    "                \n",
    "                start_idx = start_indices[0]\n",
    "                end_idx = start_idx + len(mention.split()) - 1\n",
    "                mention_span = [idxs[start_idx],idxs[end_idx]+1]\n",
    "\n",
    "        mention_spans.append(mention_span)\n",
    "\n",
    "    return mention_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "003409b1-f7e1-4ef3-99cf-8f553a85de66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [4, 6], [8, 9], [13, 14], [-1, -1], [18, 19]]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spans(gold_df[gold_df['id']=='19850315007389A']['entities'].to_list(), faa['19850315007389A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0af1a9-49a2-42dc-bd01-b7ed5ab5a7db",
   "metadata": {},
   "source": [
    "**Now, very simple to make our own version of collect_named_entities()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "664db2fc-e2ae-4029-929d-eee5f07d0d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_named_entities(entities, labels, tokens):\n",
    "    \"\"\"\n",
    "    Creates a list of Entity named-tuples, storing the entity type and the start and end\n",
    "    offsets of the entity.\n",
    "\n",
    "    Parameters:\n",
    "    - entities: [\"ENT1\",\"ENT2\"...] All entities for a doc\n",
    "    - labels: [\"LABEL1\",\"LABEL2\"...] All corresponding labels for a doc\n",
    "    - tokens: dict_values(['TOW', 'PLANE', 'BECAME', ...]) Tokenized doc. Result of faa[doc_id].values()\n",
    "\n",
    "    Returns: a list of Entity named-tuples\n",
    "    \"\"\"\n",
    "\n",
    "    ent_spans = get_spans(entities, tokens)\n",
    "\n",
    "    named_entities = []\n",
    "    for ient, ent_span in enumerate(ent_spans):\n",
    "        named_entities.append(Entity(labels[ient], ent_span[0], ent_span[1]))\n",
    "\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d4e8b446-92d3-4786-9219-d970017354cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Entity(e_type='ORG', start_offset=0, end_offset=1),\n",
       " Entity(e_type='ORG', start_offset=4, end_offset=6),\n",
       " Entity(e_type='ORG', start_offset=8, end_offset=9),\n",
       " Entity(e_type='ORG', start_offset=13, end_offset=14),\n",
       " Entity(e_type='ORG', start_offset=-1, end_offset=-1),\n",
       " Entity(e_type='ORG', start_offset=18, end_offset=19)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_named_entities(gold_df[gold_df['id']=='19850315007389A']['entities'].to_list(),gold_df[gold_df['id']=='19850315007389A']['labels'].to_list(),faa['19850315007389A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d607eb-75f6-4a38-afbc-057599e3a3e2",
   "metadata": {},
   "source": [
    "### Get Predicted and Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab72d1ac-3abb-487a-b055-e27db6a65cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_idx</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>c119_input</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19750315005389A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TAILWHEEL COCKED RIGHT PRIOR TO TKOF.         ...</td>\n",
       "      <td>tailwheel cocked right prior to tkof .</td>\n",
       "      <td>TAILWHEEL</td>\n",
       "      <td>OtherScientificTerm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19751209037899A</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>PLT NOTED SOFT R BRAKE PEDAL DRG TAXI TO TKOF....</td>\n",
       "      <td>flt rtnd springfield due soft brake strong win...</td>\n",
       "      <td>SOFT BRAKE</td>\n",
       "      <td>OtherScientificTerm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19760215007629A</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>MTNS OBSCURED.FLT TO CK VOR REC REPTD INOP PRI...</td>\n",
       "      <td>mtns obscured .</td>\n",
       "      <td>MTNS</td>\n",
       "      <td>OtherScientificTerm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19760531024959A</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>MAINT NOT PERFORMED DUE PARTS NOT AVAILABLE. T...</td>\n",
       "      <td>turbocharger waste gate did not actuate .</td>\n",
       "      <td>TURBOCHARGER WASTE GATE</td>\n",
       "      <td>OtherScientificTerm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19760507010379A</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>LEFT ENG OIL SUPPLY EXHAUSTED.GEAR-UP LDG IN M...</td>\n",
       "      <td>gear-up ldg in mesquite brush .</td>\n",
       "      <td>GEAR-UP LDG</td>\n",
       "      <td>Method</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  doc_idx  sent_idx  \\\n",
       "0  19750315005389A        0         0   \n",
       "1  19751209037899A        3         1   \n",
       "2  19760215007629A        7         0   \n",
       "3  19760531024959A        9         1   \n",
       "4  19760507010379A       10         1   \n",
       "\n",
       "                                          c119_input  \\\n",
       "0  TAILWHEEL COCKED RIGHT PRIOR TO TKOF.         ...   \n",
       "1  PLT NOTED SOFT R BRAKE PEDAL DRG TAXI TO TKOF....   \n",
       "2  MTNS OBSCURED.FLT TO CK VOR REC REPTD INOP PRI...   \n",
       "3  MAINT NOT PERFORMED DUE PARTS NOT AVAILABLE. T...   \n",
       "4  LEFT ENG OIL SUPPLY EXHAUSTED.GEAR-UP LDG IN M...   \n",
       "\n",
       "                                            sentence                 entities  \\\n",
       "0             tailwheel cocked right prior to tkof .                TAILWHEEL   \n",
       "1  flt rtnd springfield due soft brake strong win...               SOFT BRAKE   \n",
       "2                                    mtns obscured .                     MTNS   \n",
       "3          turbocharger waste gate did not actuate .  TURBOCHARGER WASTE GATE   \n",
       "4                    gear-up ldg in mesquite brush .              GEAR-UP LDG   \n",
       "\n",
       "                labels  \n",
       "0  OtherScientificTerm  \n",
       "1  OtherScientificTerm  \n",
       "2  OtherScientificTerm  \n",
       "3  OtherScientificTerm  \n",
       "4               Method  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbrevs = {'FACILITY':'FAC','ORGANIZATION':'ORG','PERSON':'PER','LOCATION':'LOC','VEH':'VEHICLE'}\n",
    "result_df = pd.read_csv('../../data/results/pl-marker/pl-marker_scierc_scibert_NER_jun17.csv')\n",
    "result_df['labels'] = result_df['labels'].apply(lambda x: abbrevs[x] if x in abbrevs else x)\n",
    "result_df.rename(columns={'c5_unique_id':'id', 'c5_id':'id'},inplace=True)\n",
    "result_df['entities'] = result_df['entities'].apply(str.upper)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5188d7e2-8c81-48ac-a7a3-7a79be703316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sample</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19990213001379A</td>\n",
       "      <td>ACFT WAS TAXIING FOR TAKE OFF WHEN IT LOST CON...</td>\n",
       "      <td>ACFT</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19990213001379A</td>\n",
       "      <td>ACFT WAS TAXIING FOR TAKE OFF WHEN IT LOST CON...</td>\n",
       "      <td>DITCH</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19990213001379A</td>\n",
       "      <td>ACFT WAS TAXIING FOR TAKE OFF WHEN IT LOST CON...</td>\n",
       "      <td>TREE</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19800217031649I</td>\n",
       "      <td>AFTER TAKEOFF, ENGINE QUIT. WING FUEL TANK SUM...</td>\n",
       "      <td>TAKEOFF</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19800217031649I</td>\n",
       "      <td>AFTER TAKEOFF, ENGINE QUIT. WING FUEL TANK SUM...</td>\n",
       "      <td>ENGINE</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                             sample  \\\n",
       "0  19990213001379A  ACFT WAS TAXIING FOR TAKE OFF WHEN IT LOST CON...   \n",
       "1  19990213001379A  ACFT WAS TAXIING FOR TAKE OFF WHEN IT LOST CON...   \n",
       "2  19990213001379A  ACFT WAS TAXIING FOR TAKE OFF WHEN IT LOST CON...   \n",
       "3  19800217031649I  AFTER TAKEOFF, ENGINE QUIT. WING FUEL TANK SUM...   \n",
       "4  19800217031649I  AFTER TAKEOFF, ENGINE QUIT. WING FUEL TANK SUM...   \n",
       "\n",
       "  entities labels  \n",
       "0     ACFT    ORG  \n",
       "1    DITCH    ORG  \n",
       "2     TREE    ORG  \n",
       "3  TAKEOFF    ORG  \n",
       "4   ENGINE    ORG  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = pd.read_csv('../../gold_standard/processed/ner.csv')\n",
    "if 'labels' not in gold_df.columns:\n",
    "    gold_df['labels'] = ['ORG']*len(gold_df) # Add dummy labels for aviation mentions-only gs\n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "339c1f06-075f-4a9a-9718-b1ff09f45e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gold_df['entities'].iat[106] = 'BARTLESVILLE' # typo in ACE-2005 Gold Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "d75052b1-240f-4597-86bb-c52b21e4d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gold_df['entities'].iat[86] = 'BARTLESVILLE' # typo in OntoNotes Gold Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0714bae2-d2da-4018-8ceb-27d6804cb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gold_df['entities'].iat[209] = 'ATTITUDE' # typo in our Gold Df\n",
    "#gold_df['entities'].iat[222] = 'ACCELARATION'\n",
    "#gold_df['entities'].iat[439] = 'MR. KADERA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dad753b-04db-4f22-863c-b124cfd2e9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1104"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_col = 'id'\n",
    "len(result_df[id_col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578e29ea-8715-46b5-b632-d958863b13b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_df['id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023a22e-4b0e-4ffe-af01-aeee59bab80f",
   "metadata": {},
   "source": [
    "**Create all_true_ents and all_pred_ents lists**\n",
    "\n",
    "In the example in example-full-named-entity-evaluation.ipynb, they use test_sents_labels and y_pred, which are lists of the tokens to input to collect_named_entities to get true and pred, respectively. However, our collect_named_entities() takes more input, so it's easier to do that process ahead of time, and have lists of true's and pred's ready to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ade105e4-959e-4e7c-9372-ebe09ba2cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_ents(true_ents):\n",
    "    final_ents = {ent:0 for ent in true_ents}\n",
    "    for ent_a in true_ents:\n",
    "        rest = [ent for ent in true_ents if ent != ent_a]\n",
    "        for ent_b in rest:\n",
    "            overlap = find_overlap(range(ent_a[1],ent_a[2]),range(ent_b[1],ent_b[2]))\n",
    "            #print(f\"Comparing {ent_a} with {ent_b}, overlap = {overlap}\")\n",
    "            if len(overlap) > 0 and len(range(ent_a[1],ent_a[2])) > len(range(ent_b[1],ent_b[2])):\n",
    "                final_ents[ent_a] += 1\n",
    "    return [ent[0] for ent in sorted(final_ents.items(), key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "816e428e-7227-4518-aca8-8ed29d1d25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_ents = []\n",
    "all_pred_ents = []\n",
    "\n",
    "for doc_id in gold_df['id'].unique():\n",
    "    true_rows = gold_df.dropna()[gold_df.dropna()['id']==doc_id]\n",
    "    pred_rows = result_df.dropna()[result_df.dropna()[id_col]==doc_id]\n",
    "\n",
    "    true_ents = collect_named_entities(true_rows['entities'].to_list(),true_rows['labels'].to_list(),faa[doc_id])\n",
    "    pred_ents = collect_named_entities(pred_rows['entities'].to_list(),pred_rows['labels'].to_list(),faa[doc_id])\n",
    "    \n",
    "    all_true_ents.append(sort_ents(true_ents))\n",
    "    all_pred_ents.append(pred_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0788059f-b8a0-47ba-9582-3b4702de2242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 19850315007389A\n",
      "[Entity(e_type='ORG', start_offset=0, end_offset=1), Entity(e_type='ORG', start_offset=4, end_offset=6), Entity(e_type='ORG', start_offset=8, end_offset=9), Entity(e_type='ORG', start_offset=13, end_offset=14), Entity(e_type='ORG', start_offset=-1, end_offset=-1), Entity(e_type='ORG', start_offset=18, end_offset=19)]\n",
      "\n",
      "True: 19801230089799I\n",
      "[Entity(e_type='ORG', start_offset=-1, end_offset=-1), Entity(e_type='ORG', start_offset=12, end_offset=13), Entity(e_type='ORG', start_offset=17, end_offset=18), Entity(e_type='ORG', start_offset=12, end_offset=14)]\n",
      "\n",
      "True: 19920405008919A\n",
      "[Entity(e_type='ORG', start_offset=1, end_offset=2), Entity(e_type='ORG', start_offset=3, end_offset=5), Entity(e_type='ORG', start_offset=8, end_offset=11), Entity(e_type='ORG', start_offset=-1, end_offset=-1), Entity(e_type='ORG', start_offset=6, end_offset=7), Entity(e_type='ORG', start_offset=3, end_offset=7)]\n",
      "\n",
      "True: 19950314029269I\n",
      "[Entity(e_type='ORG', start_offset=3, end_offset=7), Entity(e_type='ORG', start_offset=-1, end_offset=-1), Entity(e_type='ORG', start_offset=8, end_offset=9), Entity(e_type='ORG', start_offset=11, end_offset=14), Entity(e_type='ORG', start_offset=19, end_offset=20), Entity(e_type='ORG', start_offset=17, end_offset=21)]\n",
      "\n",
      "True: 20030607012509A\n",
      "[Entity(e_type='ORG', start_offset=4, end_offset=5), Entity(e_type='ORG', start_offset=10, end_offset=11), Entity(e_type='ORG', start_offset=-1, end_offset=-1), Entity(e_type='ORG', start_offset=14, end_offset=15), Entity(e_type='ORG', start_offset=16, end_offset=20), Entity(e_type='ORG', start_offset=6, end_offset=12)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idoc, doc_id in enumerate(gold_df['id'].unique()):\n",
    "    for ent in all_true_ents[idoc]:\n",
    "        if ent[1] == -1:\n",
    "            print(f\"True: {doc_id}\")\n",
    "            print(all_true_ents[idoc])\n",
    "            print()\n",
    "    for ent in all_pred_ents[idoc]:\n",
    "        if ent[1] == -1:\n",
    "            print(f\"Pred: {doc_id}\")\n",
    "            print(all_pred_ents[idoc])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a10989-debc-4445-a852-8250d9e84bc5",
   "metadata": {},
   "source": [
    "### Apply Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b47a5476-5de2-424d-844f-5222d227d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_tags = ['PER', 'ORG', 'MISC', 'LOC']\n",
    "ace_tags = ['PER','ORG','LOC','FAC','GPE'] # RESTRICTED SET\n",
    "on_tags = ['PER','ORG','LOC','FAC','GPE','PRODUCT','NORP','QUANTITY','EVENT','WORK_OF_ART','CARDINAL','DATE','PERCENT','TIME','ORDINAL','MONEY','LAW','LANGUAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e0515caa-5a88-495c-8a88-23fdbd5d0a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tags = ace_tags\n",
    "\n",
    "metrics_results = {'correct': 0, 'incorrect': 0, 'partial': 0,\n",
    "                   'missed': 0, 'spurious': 0, 'possible': 0, 'actual': 0, 'precision': 0, 'recall': 0}\n",
    "\n",
    "# overall results\n",
    "results = {'strict': deepcopy(metrics_results),\n",
    "           'ent_type': deepcopy(metrics_results),\n",
    "           'partial':deepcopy(metrics_results),\n",
    "           'exact':deepcopy(metrics_results)\n",
    "          }\n",
    "\n",
    "\n",
    "# results aggregated by entity type\n",
    "evaluation_agg_entities_type = {e: deepcopy(results) for e in tags}\n",
    "\n",
    "for true_ents, pred_ents in zip(all_true_ents, all_pred_ents):\n",
    "    \n",
    "    # compute results for one message\n",
    "    tmp_results, tmp_agg_results = compute_metrics(\n",
    "        true_ents, pred_ents,  tags\n",
    "    )\n",
    "    \n",
    "    #print(tmp_results)\n",
    "\n",
    "    # aggregate overall results\n",
    "    for eval_schema in results.keys():\n",
    "        for metric in metrics_results.keys():\n",
    "            results[eval_schema][metric] += tmp_results[eval_schema][metric]\n",
    "            \n",
    "    # Calculate global precision and recall\n",
    "        \n",
    "    results = compute_precision_recall_wrapper(results)\n",
    "\n",
    "\n",
    "    # aggregate results by entity type\n",
    " \n",
    "    for e_type in tags:\n",
    "\n",
    "        for eval_schema in tmp_agg_results[e_type]:\n",
    "\n",
    "            for metric in tmp_agg_results[e_type][eval_schema]:\n",
    "                \n",
    "                evaluation_agg_entities_type[e_type][eval_schema][metric] += tmp_agg_results[e_type][eval_schema][metric]\n",
    "                \n",
    "        # Calculate precision recall at the individual entity level\n",
    "                \n",
    "        evaluation_agg_entities_type[e_type] = compute_precision_recall_wrapper(evaluation_agg_entities_type[e_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8775604c-61d1-4809-ab59-20c1efc37c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_labeled(tool_name, results):\n",
    "\n",
    "    scores = {'exact':0.0,'strict':0.0,'partial':0.0,'ent_type':0.0}\n",
    "    for score in scores:\n",
    "        prec = results[score]['precision']\n",
    "        rec = results[score]['recall']\n",
    "        scores[score] = f\"{2*prec*rec/(prec+rec):.4}\" \n",
    "\n",
    "    print('|                                         | Strict  | Exact  | Partial  | Type    |')\n",
    "    print('|-----------------------------------------|---------|--------|----------|---------|')\n",
    "    print(f\"| {tool_name:40}| {scores['strict']:8}| {scores['exact']:7}| {scores['partial']:9}| {scores['ent_type']:8}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e534d2f1-c52b-44bd-b465-f7396b9fb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results_unlabeled(tool_name, results):\n",
    "    scores = {'exact':0.0,'partial':0.0}\n",
    "    for score in scores:\n",
    "        prec = results[score]['precision']\n",
    "        rec = results[score]['recall']\n",
    "        scores[score] = {'prec':f\"{prec:.4}\", 'rec':f\"{rec:.4}\", 'f1':f\"{(2*prec*rec/(prec+rec)):.4}\"}\n",
    "\n",
    "    print('|                                         | Precision (Weak) | Recall (Weak) | F1 (Weak)     | Precision (Strong) | Recall (Strong) | F1 (Strong) |')\n",
    "    print('|-----------------------------------------|------------------|---------------|---------------|--------------------|-----------------|-------------|')\n",
    "    print(f\"| {tool_name:40}| {scores['partial']['prec']:17}| {scores['partial']['rec']:14}| {scores['partial']['f1']:14}| {scores['exact']['prec']:19}| {scores['exact']['rec']:16}| {scores['exact']['f1']:12}|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0c46baf-b2b5-47c7-830e-91565e965062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                         | Precision (Weak) | Recall (Weak) | F1 (Weak)     | Precision (Strong) | Recall (Strong) | F1 (Strong) |\n",
      "|-----------------------------------------|------------------|---------------|---------------|--------------------|-----------------|-------------|\n",
      "| nltk (uppercased)                       | 0.1245           | 0.4286        | 0.1929        | 0.0786             | 0.2707          | 0.1218      |\n"
     ]
    }
   ],
   "source": [
    "print_results_unlabeled('nltk (uppercased)',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e4fe83b6-d37e-495a-8608-d0d609bbb690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                                         | Strict  | Exact  | Partial  | Type    |\n",
      "|-----------------------------------------|---------|--------|----------|---------|\n",
      "| nltk (uppercased)                       | 0.01015 | 0.1218 | 0.1929   | 0.03723 |\n"
     ]
    }
   ],
   "source": [
    "print_results_labeled('nltk (uppercased)',results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "728edf0d-de34-4ffc-bd8f-2e36dd4a3e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ent_type': {'correct': 11,\n",
       "  'incorrect': 67,\n",
       "  'partial': 0,\n",
       "  'missed': 55,\n",
       "  'spurious': 380,\n",
       "  'possible': 133,\n",
       "  'actual': 458,\n",
       "  'precision': 0.024017467248908297,\n",
       "  'recall': 0.08270676691729323},\n",
       " 'partial': {'correct': 36,\n",
       "  'incorrect': 0,\n",
       "  'partial': 42,\n",
       "  'missed': 55,\n",
       "  'spurious': 380,\n",
       "  'possible': 133,\n",
       "  'actual': 458,\n",
       "  'precision': 0.12445414847161572,\n",
       "  'recall': 0.42857142857142855},\n",
       " 'strict': {'correct': 3,\n",
       "  'incorrect': 75,\n",
       "  'partial': 0,\n",
       "  'missed': 55,\n",
       "  'spurious': 380,\n",
       "  'possible': 133,\n",
       "  'actual': 458,\n",
       "  'precision': 0.006550218340611353,\n",
       "  'recall': 0.022556390977443608},\n",
       " 'exact': {'correct': 36,\n",
       "  'incorrect': 42,\n",
       "  'partial': 0,\n",
       "  'missed': 55,\n",
       "  'spurious': 380,\n",
       "  'possible': 133,\n",
       "  'actual': 458,\n",
       "  'precision': 0.07860262008733625,\n",
       "  'recall': 0.2706766917293233}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f4e186f-838d-43a5-9d0f-05b49a72cf95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def orig_calculate_precision_recall_f1(gs, df_tool, id_col, ent_col, matching=\"STRONG\"):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall based on entities comparison between gs (ground truth) and df_tool (answers).\n",
    "    \n",
    "    Parameters:\n",
    "    - gs: DataFrame with columns ['id', 'sample', 'entities'] representing the ground truth.\n",
    "    - df_tool: DataFrame with columns ['id', 'sample', 'entities', 'labels'] representing the tool's answers.\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple containing precision and recall.\n",
    "    \"\"\"\n",
    "    TP = 0  # True Positives\n",
    "    FP = 0  # False Positives\n",
    "    FN = 0  # False Negatives\n",
    "    \n",
    "    # Check for True Positives and False Negatives by iterating over gs\n",
    "    for index, gs_row in gs.dropna().iterrows():\n",
    "        gs_id, gs_entity = gs_row['id'], gs_row['entities']\n",
    "        tool_entities = [entity.upper() for entity in df_tool.loc[df_tool[id_col] == gs_id, ent_col].tolist()] # get all the entities the tool generated for the gs_id entry\n",
    "        \n",
    "        # In strong matching, we only count a tool-generated entity as correct if it exactly matches the gold standard entity\n",
    "        if matching==\"STRONG\":\n",
    "            if gs_entity in tool_entities:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        # In weak matching, we count a tool-generated entity as correct if it is a subspan of the gold standard entity, or if the gold standard entity is a subspan of it\n",
    "        elif matching==\"WEAK\":\n",
    "            if any(gs_entity in tool_entity or tool_entity in gs_entity for tool_entity in tool_entities):\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        else:\n",
    "            print(\"Error: Matching must = STRONG or WEAK\")\n",
    "            return None\n",
    "    \n",
    "    # Check for False Positives by iterating over df_tool\n",
    "    for index, tool_row in df_tool[df_tool[id_col].isin(gs['id'].unique())].iterrows():\n",
    "        tool_id, tool_entity = tool_row[id_col], tool_row[ent_col]\n",
    "        gs_entities = gs.dropna().loc[gs.dropna()['id'] == tool_id, 'entities'].tolist()\n",
    "\n",
    "        #  strong matching\n",
    "        if matching==\"STRONG\":\n",
    "            if tool_entity not in gs_entities:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if not any(tool_entity in gs_entity or gs_entity in tool_entity for gs_entity in gs_entities):\n",
    "                FP += 1\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    #print(f\"TP={TP}, FP={FP}, FN={FN}, prec={precision}, rec={recall}\")\n",
    "    \n",
    "    # Calculating the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return TP, FP, FN, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6d11a9fd-e2b5-4205-aeb6-0bf636dd3b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 374, 48, 0.16143497757847533, 0.6, 0.254416961130742)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_calculate_precision_recall_f1(pd.read_csv('../../gold_standard/processed/ner_ace_nltk.csv'), pd.read_csv('../../data/results/nltk/nltk_ner_uppercased.csv'), id_col, 'entities', matching=\"WEAK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ea34e91-b9d2-4a12-b2c3-35e823458b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap(true_range, pred_range):\n",
    "    \"\"\"Find the overlap between two ranges\n",
    "\n",
    "    Find the overlap between two ranges. Return the overlapping values if\n",
    "    present, else return an empty set().\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    >>> find_overlap((1, 2), (2, 3))\n",
    "    2\n",
    "    >>> find_overlap((1, 2), (3, 4))\n",
    "    set()\n",
    "    \"\"\"\n",
    "\n",
    "    true_set = set(true_range)\n",
    "    pred_set = set(pred_range)\n",
    "\n",
    "    overlaps = true_set.intersection(pred_set)\n",
    "\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d91e7565-802f-458e-8655-c7fc2d9da6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall_f1(all_true_ents, all_pred_ents, matching=\"STRONG\"):\n",
    "    \"\"\"\n",
    "    Calculate precision and recall based on entities comparison between gs (ground truth) and df_tool (answers).\n",
    "    \n",
    "    Parameters:\n",
    "    - gs: DataFrame with columns ['id', 'sample', 'entities'] representing the ground truth.\n",
    "    - df_tool: DataFrame with columns ['id', 'sample', 'entities', 'labels'] representing the tool's answers.\n",
    "    \n",
    "    Returns:\n",
    "    - A tuple containing precision and recall.\n",
    "    \"\"\"\n",
    "    COR = 0  # correct\n",
    "    PAR = 0\n",
    "    FP = 0  # False Positives\n",
    "    FN = 0  # False Negatives\n",
    "\n",
    "    # Go doc by doc:\n",
    "    for true_ents, pred_ents in zip(all_true_ents, all_pred_ents):\n",
    "\n",
    "        unmatched_preds = [(ent[1],ent[2]) for ent in pred_ents] # copy\n",
    "\n",
    "        # Check CORs, PARs, and FNs by iterating over true ents\n",
    "        for true_ent in true_ents:\n",
    "            true_bounds = (true_ent[1],true_ent[2])\n",
    "            found_match = False\n",
    "            if true_bounds in unmatched_preds:\n",
    "                COR +=1\n",
    "                found_match = True\n",
    "                unmatched_preds.remove(true_bounds)\n",
    "            else:\n",
    "                for pred_ent in unmatched_preds:\n",
    "                    pred_bounds = (pred_ent[0],pred_ent[1])\n",
    "                    overlaps = find_overlap(true_bounds, pred_bounds)\n",
    "                    if len(overlaps) > 0:\n",
    "                        PAR += 1\n",
    "                        found_match = True\n",
    "                        unmatched_preds.remove(pred_ent)\n",
    "                        break\n",
    "            if not found_match:\n",
    "                FN += 1\n",
    "\n",
    "        FP += len(unmatched_preds)\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    if matching==\"STRONG\":\n",
    "        TP = COR\n",
    "        FP += PAR\n",
    "        FN += PAR\n",
    "    else:\n",
    "        TP = PAR + COR\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    #print(f\"TP={TP}, FP={FP}, FN={FN}, prec={precision}, rec={recall}\")\n",
    "    \n",
    "    # Calculating the F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return COR, PAR, FP, FN, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b4651865-df9a-4217-acde-ca32e030e1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 39, 379, 41, 0.17248908296943233, 0.6583333333333333, 0.27335640138408307)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_precision_recall_f1(all_true_ents, all_pred_ents,matching=\"WEAK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dfe653ca-1fa3-40ea-a018-3fc5f06e974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "davids = {'exact':{'correct':[],'incorrect':[],'partial':[],'missed':[],'spurious':[],'precision':[],'recall':[],'actual':[],'possible':[]},'partial':{'correct':[],'incorrect':[],'partial':[],'missed':[],'spurious':[],'precision':[],'recall':[],'actual':[],'possible':[]}}\n",
    "my_new = {'strong':{'COR':[],'PAR':[],'FP':[],'FN':[],'precision':[],'recall':[]},'weak':{'COR':[],'PAR':[],'FP':[],'FN':[],'precision':[],'recall':[]}}\n",
    "my_old = {'strong':{'TP':[],'FP':[],'FN':[],'precision':[],'recall':[]},'weak':{'TP':[],'FP':[],'FN':[],'precision':[],'recall':[]}}\n",
    "\n",
    "for idoc, doc_id in enumerate(gold_df['id'].unique()):\n",
    "\n",
    "    # David's way:\n",
    "    true_ents = all_true_ents[idoc]\n",
    "    pred_ents = all_pred_ents[idoc]\n",
    "    tmp_results, tmp_agg_results = compute_metrics(\n",
    "        true_ents, pred_ents,  tags\n",
    "    )\n",
    "    for type in ['exact','partial']:\n",
    "        for key in tmp_results[type].keys():\n",
    "            davids[type][key].append(tmp_results[type][key])\n",
    "\n",
    "    # My way:\n",
    "    gs = gold_df[gold_df['id']==doc_id].reset_index(drop=True)\n",
    "    df_tool = result_df[result_df[id_col]==doc_id].reset_index(drop=True)\n",
    "    for type in ['strong','weak']:\n",
    "        TP, FP, FN, prec, rec, f1 = orig_calculate_precision_recall_f1(gs, df_tool, id_col,'entities',matching=type.upper())\n",
    "        my_old[type]['TP'].append(TP)\n",
    "        my_old[type]['FP'].append(FP)\n",
    "        my_old[type]['FN'].append(FN)\n",
    "        my_old[type]['precision'].append(prec)\n",
    "        my_old[type]['recall'].append(rec)\n",
    "        \n",
    "        COR, PAR, FP, FN, prec, rec, f1 = calculate_precision_recall_f1([true_ents], [pred_ents],matching=type.upper())\n",
    "        my_new[type]['COR'].append(COR)\n",
    "        my_new[type]['PAR'].append(PAR)\n",
    "        my_new[type]['FP'].append(FP)\n",
    "        my_new[type]['FN'].append(FN)\n",
    "        my_new[type]['precision'].append(prec)\n",
    "        my_new[type]['recall'].append(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc7eb0-fcef-4312-9340-920314f347bb",
   "metadata": {},
   "source": [
    "**Compare**\n",
    "\n",
    "TP = correct + partial\\\n",
    "FP = spurious + incorrect?\\\n",
    "FN = missed + incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4776bd4-bf80-4dd1-b75b-ae5f1bb50b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(davids['exact']['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0d39aea2-fc22-4f7b-9826-c317608089f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(my_old['strong']['TP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b24b6541-3e79-4f67-8cc6-7a255a58afea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(my_new['strong']['COR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0aaa0afe-5df5-46b0-b5bb-1820c330bb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my['strong']['FP'][53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a370f4b3-8f05-4506-8216-a7d478a514d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davids['exact']['spurious'][53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d6eb28d5-2c31-44dd-a4ed-471b1bb59395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20616666666666666"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(my['strong']['recall']) # macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fb6a9b0b-aec5-4063-8671-2971d7449e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = gold_df['id'].unique()\n",
    "old_strong = my_old['strong']['TP']\n",
    "new_strong = my_new['strong']['COR']\n",
    "davids_strong = davids['exact']['correct']\n",
    "disc = map(lambda x: \"\" if x==True else \"DISC\", [old_strong[i] == new_strong[i] == davids_strong[i] for i in range(len(doc_ids))])\n",
    "\n",
    "pd.DataFrame({'id':doc_ids,'gold':[gold_df[gold_df['id']==doc_id]['entities'].to_list() for doc_id in doc_ids],'pred':[result_df[result_df[id_col]==doc_id]['entities'].to_list() for doc_id in doc_ids],'My Old':old_strong,'My New':new_strong,'Davids':davids_strong, 'DISC':disc}).to_csv('check_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6cdd9e8f-c3c8-43cd-a54c-afbc03d43b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = gold_df['id'].unique()\n",
    "old_weak = my_old['weak']['TP']\n",
    "new_weak = [my_new['weak']['COR'][i] + my_new['weak']['PAR'][i] for i in range(len(my_new['weak']['COR']))]\n",
    "davids_weak = [davids['partial']['correct'][i] + davids['partial']['partial'][i] for i in range(len(davids['partial']['correct']))]\n",
    "disc = map(lambda x: \"\" if x==True else \"DISC\", [old_weak[i] == new_weak[i] == davids_weak[i] for i in range(len(doc_ids))])\n",
    "\n",
    "pd.DataFrame({'id':doc_ids,'gold':[gold_df[gold_df['id']==doc_id]['entities'].to_list() for doc_id in doc_ids],'pred':[result_df[result_df[id_col]==doc_id]['entities'].to_list() for doc_id in doc_ids],'My Old':old_weak,'My New':new_weak,'Davids':davids_weak, 'DISC':disc}).to_csv('check_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "046b6449-69f0-4deb-acff-cdf87bb3a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 2,\n",
       " 'incorrect': 0,\n",
       " 'partial': 0,\n",
       " 'missed': 0,\n",
       " 'spurious': 2,\n",
       " 'precision': 0,\n",
       " 'recall': 0,\n",
       " 'actual': 4,\n",
       " 'possible': 2}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 53\n",
    "tmp_results, tmp_agg_results = compute_metrics(\n",
    "        all_true_ents[i], all_pred_ents[i],  tags\n",
    "    )\n",
    "tmp_results['exact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f7a6dbe-d88a-4aef-8628-ffad45429f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Entity(e_type='LOC', start_offset=1, end_offset=2),\n",
       " Entity(e_type='PER', start_offset=6, end_offset=7)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_ents[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8142c027-6e86-4a53-b658-c1d562372ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Entity(e_type='ORG', start_offset=0, end_offset=1),\n",
       " Entity(e_type='ORG', start_offset=1, end_offset=2),\n",
       " Entity(e_type='ORG', start_offset=6, end_offset=7),\n",
       " Entity(e_type='ORG', start_offset=10, end_offset=11)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_ents[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c27011f8-1c32-4963-bc35-b9bb1cd4f6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sample</th>\n",
       "      <th>entities</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>19861114075329I</td>\n",
       "      <td>ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...</td>\n",
       "      <td>TCA</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>19861114075329I</td>\n",
       "      <td>ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                             sample  \\\n",
       "78  19861114075329I  ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...   \n",
       "79  19861114075329I  ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...   \n",
       "\n",
       "   entities labels  \n",
       "78      TCA    LOC  \n",
       "79    PILOT    PER  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df[gold_df['id']==gold_df['id'].unique()[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eef7cf04-a750-4bc8-a584-9be896658a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>c5_unique_id</th>\n",
       "      <th>c119_text</th>\n",
       "      <th>entities</th>\n",
       "      <th>POS tags</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1117</td>\n",
       "      <td>19861114075329I</td>\n",
       "      <td>ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...</td>\n",
       "      <td>ENTERED</td>\n",
       "      <td>NNP</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1117</td>\n",
       "      <td>19861114075329I</td>\n",
       "      <td>ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...</td>\n",
       "      <td>TCA</td>\n",
       "      <td>NNP</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1117</td>\n",
       "      <td>19861114075329I</td>\n",
       "      <td>ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...</td>\n",
       "      <td>PILOT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1117</td>\n",
       "      <td>19861114075329I</td>\n",
       "      <td>ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...</td>\n",
       "      <td>MALFUNCTIONING</td>\n",
       "      <td>NNP</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index     c5_unique_id  \\\n",
       "236   1117  19861114075329I   \n",
       "237   1117  19861114075329I   \n",
       "238   1117  19861114075329I   \n",
       "239   1117  19861114075329I   \n",
       "\n",
       "                                             c119_text        entities  \\\n",
       "236  ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...         ENTERED   \n",
       "237  ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...             TCA   \n",
       "238  ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...           PILOT   \n",
       "239  ENTERED TCA WITHOUT ATC COMMUNICATION. PILOT W...  MALFUNCTIONING   \n",
       "\n",
       "    POS tags labels  \n",
       "236      NNP    ORG  \n",
       "237      NNP    ORG  \n",
       "238      NNP    ORG  \n",
       "239      NNP    ORG  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df[id_col]==gold_df['id'].unique()[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91564576-a861-4854-a0f8-ac41862a94d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'ENTERED',\n",
       " 1: 'TCA',\n",
       " 2: 'WITHOUT',\n",
       " 3: 'ATC',\n",
       " 4: 'COMMUNICATION',\n",
       " 5: '/.',\n",
       " 6: 'PILOT',\n",
       " 7: 'WAS',\n",
       " 8: 'AWARE',\n",
       " 9: 'OF',\n",
       " 10: 'MALFUNCTIONING',\n",
       " 11: 'ENCODING',\n",
       " 12: 'ALTIMETER',\n",
       " 13: '/.'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faa[gold_df['id'].unique()[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bfc388-8464-4e2b-b3db-dbff77e126eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
