{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a5eff5a-072d-477f-955d-056ca5878fdc",
   "metadata": {},
   "source": [
    "# Prepare and standardize the gold standard data\n",
    "\n",
    "From ``raw/*.cvs`` to ``procesed/*.csv``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f8157-d6a4-4850-8dc4-b144bf6422a2",
   "metadata": {},
   "source": [
    "## Gold standard NER data\n",
    "\n",
    "Un-typed NER GS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccc6dc-9cde-496c-bc35-006c4531ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "gold_standard_path = 'raw/ner.csv'\n",
    "data = pd.read_csv(gold_standard_path)\n",
    "\n",
    "\n",
    "# rename columns\n",
    "columns={\"c5_unique_id\": \"id\", \"c119_text\": \"sample\", \"GS\":\"entities\"}\n",
    "data.rename(columns=columns, inplace=True)\n",
    "\n",
    "data = data[['id', 'sample', 'entities']]\n",
    "\n",
    "# Remove spaces within entities, split by comma, then explode\n",
    "data['entities'] = data['entities'].apply(lambda x: [] if type(x) != str else ast.literal_eval(x))\n",
    "data = data[['id','sample','entities']].explode('entities').reset_index(drop=True)\n",
    "\n",
    "# check for errors -- entities which don't match literal text mentions\n",
    "for sample, entity in zip(data['sample'],data['entities']):\n",
    "        if entity != None and entity not in sample:\n",
    "            print(sample, entity)\n",
    "\n",
    "# Save the processed tool output to a file\n",
    "data.to_csv('processed/ner.csv', index=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1137a54-2f9a-4a99-96e5-a140dbfc5eee",
   "metadata": {},
   "source": [
    "### Benchmark-Annotated Gold Standard NER Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452ff73-1fba-491e-941c-bc1d9d9e78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "gold_standard_path = 'raw/ner_benchmarks_gold.csv'\n",
    "original_data = pd.read_csv(gold_standard_path, skiprows=8, header=0)\n",
    "\n",
    "for bench in ['conll','ace','on']:\n",
    "\n",
    "    columns={\"c5_unique_id\": \"id\", \"c119_text\": \"sample\", bench+\"_ents\":\"entities\",bench+\"_labels\":\"labels\"}\n",
    "    data = original_data.rename(columns=columns)\n",
    "    \n",
    "    data = data[['id', 'sample', 'entities','labels']]\n",
    "    \n",
    "    # Get lists of entities and labels from strings\n",
    "    data['entities'] = data['entities'].apply(lambda x: [] if type(x) != str else ast.literal_eval(x))\n",
    "    data['labels'] = data['labels'].apply(lambda x: [] if type(x) != str else ast.literal_eval(x))\n",
    "    \n",
    "    # Explode\n",
    "    data = pd.concat([data[['id','sample','entities']].explode('entities').reset_index(drop=True), data['labels'].explode('labels').reset_index(drop=True)], axis=1)\n",
    "\n",
    "    # check for errors -- entities which don't match literal text mentions\n",
    "    for sample, entity in zip(data['sample'],data['entities']):\n",
    "            if type(entity) == str and entity not in sample:\n",
    "                print(sample, entity)\n",
    "    \n",
    "    #save\n",
    "    data.to_csv(f'processed/ner_{bench}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178c912-8f99-4606-92b5-c9b552ecc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make ACE-Phase 1 GS with restricted set of labels used by NLTK\n",
    "\n",
    "gold_standard_path = 'raw/ner_benchmarks_gold.csv'\n",
    "original_data = pd.read_csv(gold_standard_path, skiprows=8, header=0)\n",
    "\n",
    "bench = 'ace'\n",
    "\n",
    "columns={\"c5_unique_id\": \"id\", \"c119_text\": \"sample\", bench+\"_ents\":\"entities\",bench+\"_labels\":\"labels\"}\n",
    "data = original_data.rename(columns=columns)\n",
    "\n",
    "data = data[['id', 'sample', 'entities','labels']]\n",
    "\n",
    "# Get lists of entities and labels from strings\n",
    "data['entities'] = data['entities'].apply(lambda x: [] if type(x) != str else ast.literal_eval(x))\n",
    "data['labels'] = data['labels'].apply(lambda x: [] if type(x) != str else ast.literal_eval(x))\n",
    "\n",
    "# Remove \"VEHICLE\" entities and labels\n",
    "for i in range(len(data)):\n",
    "    while \"VEHICLE\" in data['labels'].iat[i]:\n",
    "        vehicle_idx = data['labels'].iat[i].index(\"VEHICLE\")\n",
    "        data['entities'].iat[i] = data['entities'].iat[i][:vehicle_idx] + data['entities'].iat[i][vehicle_idx+1:]\n",
    "        data['labels'].iat[i] = data['labels'].iat[i][:vehicle_idx] + data['labels'].iat[i][vehicle_idx+1:]\n",
    "\n",
    "# Explode\n",
    "data = pd.concat([data[['id','sample','entities']].explode('entities').reset_index(drop=True), data['labels'].explode('labels').reset_index(drop=True)], axis=1)\n",
    "\n",
    "# check for errors -- entities which don't match literal text mentions\n",
    "for sample, entity in zip(data['sample'],data['entities']):\n",
    "        if type(entity) == str and entity not in sample:\n",
    "            print(sample, entity)\n",
    "\n",
    "#save\n",
    "data.to_csv(f'processed/ner_ace_nltk.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b103e4-d42a-4c71-82af-2505c3353b5c",
   "metadata": {},
   "source": [
    "## Gold Standard CR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a916718-7127-4608-8a96-31280e226152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gold_standard_path = 'raw/cr.csv'\n",
    "data = pd.read_csv(gold_standard_path)\n",
    "\n",
    "data.rename(columns={\"c5\": \"id\", \"c119_text\": \"sample\",'coreferences':'coreferences'}, inplace=True)\n",
    "\n",
    "# Save the processed tool output to a file\n",
    "data[['id','sample','coreferences']].to_csv('processed/cr.csv', index=False)\n",
    "data[['id','sample','coreferences']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7b428-fff0-4623-a737-3273331ddbb5",
   "metadata": {},
   "source": [
    "## Gold standard NEL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b80913-9d2f-4566-8d68-33a31d617e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "gold_standard_path = 'raw/nel.csv'\n",
    "data = pd.read_csv(gold_standard_path)\n",
    "\n",
    "# rename columns\n",
    "data.rename(columns={\"c5_unique_id\": \"id\", \"c119_text\": \"sample\"}, inplace=True)\n",
    "data['entity'] = range(len(data))\n",
    "data['qid'] = range(len(data))\n",
    "\n",
    "# compile primary, secondary, and tertiary entities and qids into parallel lists\n",
    "prefixes = ['primary_','secondary_','tertiary_']\n",
    "data['entity'] = data['entity'].apply(lambda i: [data[prefix+'ent'].iat[i] if type(data[prefix+'ent'].iat[i])==str else None for prefix in prefixes])\n",
    "data['qid'] = data['qid'].apply(lambda i: [data[prefix+'qid'].iat[i] if type(data[prefix+'qid'].iat[i])==str else None for prefix in prefixes])\n",
    "\n",
    "# check for errors -- entities which don't match literal text mentions\n",
    "for sample, entity in zip(data['sample'],data['entity']):\n",
    "    for ent in entity:\n",
    "        if ent != None and ent not in sample:\n",
    "            print(sample, ent)\n",
    "\n",
    "# Save the processed tool output to a file\n",
    "data[['id','sample','entity','qid']].to_csv('processed/nel.csv', index=False)\n",
    "data[['id','sample','entity','qid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4eec9-6f52-49c2-86c8-591a7deff715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
